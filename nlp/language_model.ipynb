{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tud\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "BATCH_SIZE = 32\n",
    "sequence_len = 50\n",
    "vocab_size = 30000\n",
    "train_file, dev_file, test_file = [os.path.join('./data', file) \\\n",
    "                                   for file in ['text8.train', 'text8.dev', 'text8.test']]\n",
    "train_raw = open(train_file).readlines()[0]\n",
    "dev_raw = open(dev_file).readlines()[0]\n",
    "test_raw = open(test_file).readlines()[0]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "vocab = Counter(train_raw.split(' ')).most_common(vocab_size - 1)\n",
    "idx_to_word = [item[0] for item in vocab]\n",
    "idx_to_word.append('UNK')\n",
    "word_to_idx = {word: i for i, word in enumerate(idx_to_word)}\n",
    "\n",
    "class LanguageDataset(tud.Dataset):\n",
    "    def __init__(self, text, sequence_len, idx_to_word, word_to_idx, vocab_size, device):\n",
    "        super(LanguageDataset, self).__init__()\n",
    "        self.device = device\n",
    "        self.vocab_size = vocab_size\n",
    "        self.idx_to_word = idx_to_word\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.word_encode = [self.word_to_idx.get(word, self.vocab_size - 1) for word in text]\n",
    "        self.word_encode = torch.LongTensor(self.word_encode).to(device)\n",
    "        self.sequence_len = sequence_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word_encode) - self.sequence_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.word_encode[idx: min(idx + self.sequence_len, len(self.word_encode) - 1)]\n",
    "        y = self.word_encode[idx + 1: min(idx + self.sequence_len + 1, len(self.word_encode))]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "train_data = LanguageDataset(train_raw, sequence_len, idx_to_word, word_to_idx, vocab_size, device)\n",
    "dev_data = LanguageDataset(dev_raw, sequence_len, idx_to_word, word_to_idx, vocab_size, device)\n",
    "test_data = LanguageDataset(test_raw, sequence_len, idx_to_word, word_to_idx, vocab_size, device)\n",
    "train_iter = tud.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "dev_iter = tud.DataLoader(dev_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_iter = tud.DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50])\n",
      "torch.Size([32, 50])\n",
      "a n d UNK p i c n i c s UNK a c r o s s UNK a r g e n t i n a UNK v e g e t a b l e s UNK a n d UNK s a l a d s\n",
      "n d UNK p i c n i c s UNK a c r o s s UNK a r g e n t i n a UNK v e g e t a b l e s UNK a n d UNK s a l a d s UNK\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(train_iter):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(' '.join([idx_to_word[idx] for idx in x[0]]))\n",
    "    print(' '.join([idx_to_word[idx] for idx in y[0]]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "import torch\n",
    "embed_size, hidden_size = 300, 1000\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        init_range = 0.5 / vocab_size\n",
    "        self.embed.weight.data.uniform_(-init_range, init_range)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        input_x = self.embed(x)     #batch_size * sequence_len * embedding_size\n",
    "        output, hidden = self.lstm(input_x, hidden)  #output: batch_size * sequence_len * embedding_size\n",
    "        output_vocab = self.linear(output)   #output_vocab:  batch_size * sequence_len * vocab_size\n",
    "        return output_vocab, hidden\n",
    "    \n",
    "    def init_hidden(self, bsz, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros((1, bsz, self.hidden_size), requires_grad=requires_grad),\n",
    "                    weight.new_zeros((1, bsz, self.hidden_size), requires_grad=requires_grad))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 0, train loss: 10.30607795715332\n",
      "Epoch: 0, iter: 100, train loss: 10.30573844909668\n",
      "Epoch: 0, iter: 200, train loss: 10.304821968078613\n",
      "Epoch: 0, iter: 300, train loss: 10.305386543273926\n",
      "Epoch: 0, iter: 400, train loss: 10.305276870727539\n",
      "Epoch: 0, iter: 500, train loss: 10.305619239807129\n",
      "Epoch: 0, iter: 1000, train loss: 10.305541038513184\n",
      "Epoch: 0, iter: 1100, train loss: 10.304949760437012\n",
      "Epoch: 0, iter: 1200, train loss: 10.305624008178711\n",
      "Epoch: 0, iter: 1300, train loss: 10.30508041381836\n",
      "Epoch: 0, iter: 1400, train loss: 10.304722785949707\n",
      "Epoch: 0, iter: 1500, train loss: 10.305615425109863\n",
      "Epoch: 0, iter: 1600, train loss: 10.305436134338379\n",
      "Epoch: 0, iter: 1700, train loss: 10.305097579956055\n",
      "Epoch: 0, iter: 1800, train loss: 10.305451393127441\n",
      "Epoch: 0, iter: 1900, train loss: 10.304823875427246\n",
      "Epoch: 0, iter: 2000, train loss: 10.305272102355957\n",
      "Epoch: 0, iter: 2100, train loss: 10.305196762084961\n",
      "Epoch: 0, iter: 2200, train loss: 10.305206298828125\n",
      "Epoch: 0, iter: 2300, train loss: 10.30583381652832\n",
      "Epoch: 0, iter: 2400, train loss: 10.305904388427734\n",
      "Epoch: 0, iter: 2500, train loss: 10.306011199951172\n",
      "Epoch: 0, iter: 2600, train loss: 10.305822372436523\n",
      "Epoch: 0, iter: 2700, train loss: 10.30447006225586\n",
      "Epoch: 0, iter: 2800, train loss: 10.305676460266113\n",
      "Epoch: 0, iter: 2900, train loss: 10.305027961730957\n",
      "Epoch: 0, iter: 3000, train loss: 10.304930686950684\n",
      "Epoch: 0, iter: 3100, train loss: 10.305578231811523\n",
      "Epoch: 0, iter: 3200, train loss: 10.304879188537598\n",
      "Epoch: 0, iter: 3300, train loss: 10.305065155029297\n",
      "Epoch: 0, iter: 3400, train loss: 10.30493450164795\n",
      "Epoch: 0, iter: 3500, train loss: 10.304744720458984\n",
      "Epoch: 0, iter: 3600, train loss: 10.305015563964844\n",
      "Epoch: 0, iter: 3700, train loss: 10.305712699890137\n",
      "Epoch: 0, iter: 3800, train loss: 10.304747581481934\n",
      "Epoch: 0, iter: 3900, train loss: 10.305645942687988\n",
      "Epoch: 0, iter: 4000, train loss: 10.305529594421387\n",
      "Epoch: 0, iter: 4100, train loss: 10.305868148803711\n",
      "Epoch: 0, iter: 4200, train loss: 10.305376052856445\n",
      "Epoch: 0, iter: 4300, train loss: 10.305991172790527\n",
      "Epoch: 0, iter: 4400, train loss: 10.304998397827148\n",
      "Epoch: 0, iter: 4500, train loss: 10.30487060546875\n",
      "Epoch: 0, iter: 4600, train loss: 10.305078506469727\n",
      "Epoch: 0, iter: 4700, train loss: 10.305115699768066\n",
      "Epoch: 0, iter: 4800, train loss: 10.304888725280762\n",
      "Epoch: 0, iter: 4900, train loss: 10.305061340332031\n",
      "Epoch: 0, iter: 5000, train loss: 10.30495834350586\n",
      "Epoch: 0, iter: 5100, train loss: 10.304516792297363\n",
      "Epoch: 0, iter: 5200, train loss: 10.305829048156738\n",
      "Epoch: 0, iter: 5300, train loss: 10.306422233581543\n",
      "Epoch: 0, iter: 5400, train loss: 10.304810523986816\n",
      "Epoch: 0, iter: 5500, train loss: 10.305275917053223\n",
      "Epoch: 0, iter: 5600, train loss: 10.305102348327637\n",
      "Epoch: 0, iter: 5700, train loss: 10.304608345031738\n",
      "Epoch: 0, iter: 5800, train loss: 10.305027961730957\n",
      "Epoch: 0, iter: 5900, train loss: 10.305217742919922\n",
      "Epoch: 0, iter: 6000, train loss: 10.306286811828613\n",
      "Epoch: 0, iter: 6100, train loss: 10.3049898147583\n",
      "Epoch: 0, iter: 6200, train loss: 10.306142807006836\n",
      "Epoch: 0, iter: 6300, train loss: 10.305107116699219\n",
      "Epoch: 0, iter: 6400, train loss: 10.304713249206543\n",
      "Epoch: 0, iter: 6500, train loss: 10.30526351928711\n",
      "Epoch: 0, iter: 6600, train loss: 10.305267333984375\n",
      "Epoch: 0, iter: 6700, train loss: 10.305015563964844\n",
      "Epoch: 0, iter: 6800, train loss: 10.306201934814453\n",
      "Epoch: 0, iter: 6900, train loss: 10.305584907531738\n",
      "Epoch: 0, iter: 7000, train loss: 10.304579734802246\n",
      "Epoch: 0, iter: 7100, train loss: 10.305187225341797\n",
      "Epoch: 0, iter: 7200, train loss: 10.305523872375488\n",
      "Epoch: 0, iter: 7300, train loss: 10.305464744567871\n",
      "Epoch: 0, iter: 7400, train loss: 10.304313659667969\n",
      "Epoch: 0, iter: 7500, train loss: 10.305070877075195\n",
      "Epoch: 0, iter: 7600, train loss: 10.305506706237793\n",
      "Epoch: 0, iter: 7700, train loss: 10.304498672485352\n",
      "Epoch: 0, iter: 7800, train loss: 10.304697036743164\n",
      "Epoch: 0, iter: 7900, train loss: 10.305594444274902\n",
      "Epoch: 0, iter: 8000, train loss: 10.305200576782227\n",
      "Epoch: 0, iter: 8100, train loss: 10.305266380310059\n",
      "Epoch: 0, iter: 8200, train loss: 10.304495811462402\n",
      "Epoch: 0, iter: 8300, train loss: 10.304618835449219\n",
      "Epoch: 0, iter: 8400, train loss: 10.305771827697754\n",
      "Epoch: 0, iter: 8500, train loss: 10.304851531982422\n",
      "Epoch: 0, iter: 8600, train loss: 10.305608749389648\n",
      "Epoch: 0, iter: 8700, train loss: 10.305432319641113\n",
      "Epoch: 0, iter: 8800, train loss: 10.305805206298828\n",
      "Epoch: 0, iter: 8900, train loss: 10.305933952331543\n",
      "Epoch: 0, iter: 9000, train loss: 10.304950714111328\n",
      "Epoch: 0, iter: 9100, train loss: 10.305721282958984\n",
      "Epoch: 0, iter: 9200, train loss: 10.30504035949707\n",
      "Epoch: 0, iter: 9300, train loss: 10.305634498596191\n",
      "Epoch: 0, iter: 9400, train loss: 10.305070877075195\n",
      "Epoch: 0, iter: 9500, train loss: 10.305824279785156\n",
      "Epoch: 0, iter: 9600, train loss: 10.305990219116211\n",
      "Epoch: 0, iter: 9700, train loss: 10.304393768310547\n",
      "Epoch: 0, iter: 9800, train loss: 10.30502700805664\n",
      "Epoch: 0, iter: 9900, train loss: 10.304766654968262\n",
      "Epoch: 0, iter: 10000, train loss: 10.305868148803711\n",
      "Epoch: 0, iter: 10100, train loss: 10.306082725524902\n",
      "Epoch: 0, iter: 10200, train loss: 10.305736541748047\n",
      "Epoch: 0, iter: 10300, train loss: 10.304805755615234\n",
      "Epoch: 0, iter: 10400, train loss: 10.305144309997559\n",
      "Epoch: 0, iter: 10500, train loss: 10.305907249450684\n",
      "Epoch: 0, iter: 10600, train loss: 10.305588722229004\n",
      "Epoch: 0, iter: 10700, train loss: 10.305459976196289\n",
      "Epoch: 0, iter: 10800, train loss: 10.304656028747559\n",
      "Epoch: 0, iter: 10900, train loss: 10.306156158447266\n",
      "Epoch: 0, iter: 11000, train loss: 10.305551528930664\n",
      "Epoch: 0, iter: 11100, train loss: 10.306256294250488\n",
      "Epoch: 0, iter: 11200, train loss: 10.304569244384766\n",
      "Epoch: 0, iter: 11300, train loss: 10.304925918579102\n",
      "Epoch: 0, iter: 11400, train loss: 10.305954933166504\n",
      "Epoch: 0, iter: 11500, train loss: 10.30542278289795\n",
      "Epoch: 0, iter: 11600, train loss: 10.305624008178711\n",
      "Epoch: 0, iter: 11700, train loss: 10.305871963500977\n",
      "Epoch: 0, iter: 11800, train loss: 10.305342674255371\n",
      "Epoch: 0, iter: 11900, train loss: 10.304494857788086\n",
      "Epoch: 0, iter: 12000, train loss: 10.305083274841309\n",
      "Epoch: 0, iter: 12100, train loss: 10.304981231689453\n",
      "Epoch: 0, iter: 12200, train loss: 10.305268287658691\n",
      "Epoch: 0, iter: 12300, train loss: 10.304520606994629\n",
      "Epoch: 0, iter: 12400, train loss: 10.305919647216797\n",
      "Epoch: 0, iter: 12500, train loss: 10.3054838180542\n",
      "Epoch: 0, iter: 12600, train loss: 10.305146217346191\n",
      "Epoch: 0, iter: 12700, train loss: 10.305929183959961\n",
      "Epoch: 0, iter: 12800, train loss: 10.305750846862793\n",
      "Epoch: 0, iter: 12900, train loss: 10.305652618408203\n",
      "Epoch: 0, iter: 13000, train loss: 10.305438995361328\n",
      "Epoch: 0, iter: 13100, train loss: 10.304129600524902\n",
      "Epoch: 0, iter: 13200, train loss: 10.305854797363281\n",
      "Epoch: 0, iter: 13300, train loss: 10.305188179016113\n",
      "Epoch: 0, iter: 13400, train loss: 10.305035591125488\n",
      "Epoch: 0, iter: 13500, train loss: 10.305063247680664\n",
      "Epoch: 0, iter: 13600, train loss: 10.304962158203125\n",
      "Epoch: 0, iter: 13700, train loss: 10.304644584655762\n",
      "Epoch: 0, iter: 13800, train loss: 10.304492950439453\n",
      "Epoch: 0, iter: 13900, train loss: 10.305554389953613\n",
      "Epoch: 0, iter: 14000, train loss: 10.3057279586792\n",
      "Epoch: 0, iter: 14100, train loss: 10.305554389953613\n",
      "Epoch: 0, iter: 14200, train loss: 10.304923057556152\n",
      "Epoch: 0, iter: 14300, train loss: 10.305854797363281\n",
      "Epoch: 0, iter: 14400, train loss: 10.30465316772461\n",
      "Epoch: 0, iter: 14500, train loss: 10.305294036865234\n",
      "Epoch: 0, iter: 14600, train loss: 10.306291580200195\n",
      "Epoch: 0, iter: 14700, train loss: 10.305550575256348\n",
      "Epoch: 0, iter: 14800, train loss: 10.30444049835205\n",
      "Epoch: 0, iter: 14900, train loss: 10.305039405822754\n",
      "Epoch: 0, iter: 15000, train loss: 10.305890083312988\n",
      "Epoch: 0, iter: 15100, train loss: 10.305563926696777\n",
      "Epoch: 0, iter: 15200, train loss: 10.305870056152344\n",
      "Epoch: 0, iter: 15300, train loss: 10.306097030639648\n",
      "Epoch: 0, iter: 15400, train loss: 10.30600357055664\n",
      "Epoch: 0, iter: 15500, train loss: 10.306374549865723\n",
      "Epoch: 0, iter: 15600, train loss: 10.305023193359375\n",
      "Epoch: 0, iter: 15700, train loss: 10.304849624633789\n",
      "Epoch: 0, iter: 15800, train loss: 10.305617332458496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 15900, train loss: 10.305420875549316\n",
      "Epoch: 0, iter: 16000, train loss: 10.304740905761719\n",
      "Epoch: 0, iter: 16100, train loss: 10.304905891418457\n",
      "Epoch: 0, iter: 16200, train loss: 10.305919647216797\n",
      "Epoch: 0, iter: 16300, train loss: 10.305276870727539\n",
      "Epoch: 0, iter: 16400, train loss: 10.305904388427734\n",
      "Epoch: 0, iter: 16500, train loss: 10.305615425109863\n",
      "Epoch: 0, iter: 16600, train loss: 10.304744720458984\n",
      "Epoch: 0, iter: 16700, train loss: 10.304800987243652\n",
      "Epoch: 0, iter: 16800, train loss: 10.305512428283691\n",
      "Epoch: 0, iter: 16900, train loss: 10.304861068725586\n",
      "Epoch: 0, iter: 17000, train loss: 10.304634094238281\n",
      "Epoch: 0, iter: 17100, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 17200, train loss: 10.30462646484375\n",
      "Epoch: 0, iter: 17300, train loss: 10.306146621704102\n",
      "Epoch: 0, iter: 17400, train loss: 10.305891990661621\n",
      "Epoch: 0, iter: 17500, train loss: 10.305103302001953\n",
      "Epoch: 0, iter: 17600, train loss: 10.305541038513184\n",
      "Epoch: 0, iter: 17700, train loss: 10.305115699768066\n",
      "Epoch: 0, iter: 17800, train loss: 10.305473327636719\n",
      "Epoch: 0, iter: 17900, train loss: 10.304841041564941\n",
      "Epoch: 0, iter: 18000, train loss: 10.304956436157227\n",
      "Epoch: 0, iter: 18100, train loss: 10.305695533752441\n",
      "Epoch: 0, iter: 18200, train loss: 10.304914474487305\n",
      "Epoch: 0, iter: 18300, train loss: 10.306251525878906\n",
      "Epoch: 0, iter: 18400, train loss: 10.306174278259277\n",
      "Epoch: 0, iter: 18500, train loss: 10.306068420410156\n",
      "Epoch: 0, iter: 18600, train loss: 10.305026054382324\n",
      "Epoch: 0, iter: 18700, train loss: 10.305274963378906\n",
      "Epoch: 0, iter: 18800, train loss: 10.30517292022705\n",
      "Epoch: 0, iter: 18900, train loss: 10.304828643798828\n",
      "Epoch: 0, iter: 19000, train loss: 10.305598258972168\n",
      "Epoch: 0, iter: 19100, train loss: 10.305512428283691\n",
      "Epoch: 0, iter: 19200, train loss: 10.305817604064941\n",
      "Epoch: 0, iter: 19300, train loss: 10.305200576782227\n",
      "Epoch: 0, iter: 19400, train loss: 10.305747985839844\n",
      "Epoch: 0, iter: 19500, train loss: 10.304726600646973\n",
      "Epoch: 0, iter: 19600, train loss: 10.304546356201172\n",
      "Epoch: 0, iter: 19700, train loss: 10.305405616760254\n",
      "Epoch: 0, iter: 19800, train loss: 10.305131912231445\n",
      "Epoch: 0, iter: 19900, train loss: 10.305508613586426\n",
      "Epoch: 0, iter: 20000, train loss: 10.30566692352295\n",
      "Epoch: 0, iter: 20100, train loss: 10.30502700805664\n",
      "Epoch: 0, iter: 20200, train loss: 10.30517864227295\n",
      "Epoch: 0, iter: 20300, train loss: 10.304876327514648\n",
      "Epoch: 0, iter: 20400, train loss: 10.305402755737305\n",
      "Epoch: 0, iter: 20500, train loss: 10.305785179138184\n",
      "Epoch: 0, iter: 20600, train loss: 10.305929183959961\n",
      "Epoch: 0, iter: 20700, train loss: 10.3051118850708\n",
      "Epoch: 0, iter: 20800, train loss: 10.305109977722168\n",
      "Epoch: 0, iter: 20900, train loss: 10.306197166442871\n",
      "Epoch: 0, iter: 21000, train loss: 10.3047513961792\n",
      "Epoch: 0, iter: 21100, train loss: 10.305319786071777\n",
      "Epoch: 0, iter: 21200, train loss: 10.305110931396484\n",
      "Epoch: 0, iter: 21300, train loss: 10.305572509765625\n",
      "Epoch: 0, iter: 21400, train loss: 10.305673599243164\n",
      "Epoch: 0, iter: 21500, train loss: 10.305036544799805\n",
      "Epoch: 0, iter: 21600, train loss: 10.305546760559082\n",
      "Epoch: 0, iter: 21700, train loss: 10.304591178894043\n",
      "Epoch: 0, iter: 21800, train loss: 10.305558204650879\n",
      "Epoch: 0, iter: 21900, train loss: 10.30526351928711\n",
      "Epoch: 0, iter: 22000, train loss: 10.304853439331055\n",
      "Epoch: 0, iter: 22100, train loss: 10.305207252502441\n",
      "Epoch: 0, iter: 22200, train loss: 10.305197715759277\n",
      "Epoch: 0, iter: 22300, train loss: 10.304590225219727\n",
      "Epoch: 0, iter: 22400, train loss: 10.305632591247559\n",
      "Epoch: 0, iter: 22500, train loss: 10.305816650390625\n",
      "Epoch: 0, iter: 22600, train loss: 10.306109428405762\n",
      "Epoch: 0, iter: 22700, train loss: 10.303256034851074\n",
      "Epoch: 0, iter: 22800, train loss: 10.30495834350586\n",
      "Epoch: 0, iter: 22900, train loss: 10.30490493774414\n",
      "Epoch: 0, iter: 23000, train loss: 10.30504035949707\n",
      "Epoch: 0, iter: 23100, train loss: 10.305816650390625\n",
      "Epoch: 0, iter: 23200, train loss: 10.305964469909668\n",
      "Epoch: 0, iter: 23300, train loss: 10.305726051330566\n",
      "Epoch: 0, iter: 23400, train loss: 10.30456829071045\n",
      "Epoch: 0, iter: 23500, train loss: 10.305617332458496\n",
      "Epoch: 0, iter: 23600, train loss: 10.305402755737305\n",
      "Epoch: 0, iter: 23700, train loss: 10.305419921875\n",
      "Epoch: 0, iter: 23800, train loss: 10.304791450500488\n",
      "Epoch: 0, iter: 23900, train loss: 10.305124282836914\n",
      "Epoch: 0, iter: 24000, train loss: 10.30538558959961\n",
      "Epoch: 0, iter: 24100, train loss: 10.305887222290039\n",
      "Epoch: 0, iter: 24200, train loss: 10.305246353149414\n",
      "Epoch: 0, iter: 24300, train loss: 10.305516242980957\n",
      "Epoch: 0, iter: 24400, train loss: 10.305389404296875\n",
      "Epoch: 0, iter: 24500, train loss: 10.305468559265137\n",
      "Epoch: 0, iter: 24600, train loss: 10.305201530456543\n",
      "Epoch: 0, iter: 24700, train loss: 10.304983139038086\n",
      "Epoch: 0, iter: 24800, train loss: 10.305148124694824\n",
      "Epoch: 0, iter: 24900, train loss: 10.305145263671875\n",
      "Epoch: 0, iter: 25000, train loss: 10.30598258972168\n",
      "Epoch: 0, iter: 25100, train loss: 10.305517196655273\n",
      "Epoch: 0, iter: 25200, train loss: 10.305581092834473\n",
      "Epoch: 0, iter: 25300, train loss: 10.305939674377441\n",
      "Epoch: 0, iter: 25400, train loss: 10.305322647094727\n",
      "Epoch: 0, iter: 25500, train loss: 10.304343223571777\n",
      "Epoch: 0, iter: 25600, train loss: 10.305334091186523\n",
      "Epoch: 0, iter: 25700, train loss: 10.30562973022461\n",
      "Epoch: 0, iter: 25800, train loss: 10.304168701171875\n",
      "Epoch: 0, iter: 25900, train loss: 10.305447578430176\n",
      "Epoch: 0, iter: 26000, train loss: 10.305301666259766\n",
      "Epoch: 0, iter: 26100, train loss: 10.306478500366211\n",
      "Epoch: 0, iter: 26200, train loss: 10.305449485778809\n",
      "Epoch: 0, iter: 26300, train loss: 10.305078506469727\n",
      "Epoch: 0, iter: 26400, train loss: 10.306695938110352\n",
      "Epoch: 0, iter: 26500, train loss: 10.305133819580078\n",
      "Epoch: 0, iter: 26600, train loss: 10.305347442626953\n",
      "Epoch: 0, iter: 26700, train loss: 10.305231094360352\n",
      "Epoch: 0, iter: 26800, train loss: 10.305397033691406\n",
      "Epoch: 0, iter: 26900, train loss: 10.305581092834473\n",
      "Epoch: 0, iter: 27000, train loss: 10.304277420043945\n",
      "Epoch: 0, iter: 27100, train loss: 10.3049955368042\n",
      "Epoch: 0, iter: 27200, train loss: 10.305712699890137\n",
      "Epoch: 0, iter: 27300, train loss: 10.304932594299316\n",
      "Epoch: 0, iter: 27400, train loss: 10.304011344909668\n",
      "Epoch: 0, iter: 27500, train loss: 10.305402755737305\n",
      "Epoch: 0, iter: 27600, train loss: 10.305838584899902\n",
      "Epoch: 0, iter: 27700, train loss: 10.306143760681152\n",
      "Epoch: 0, iter: 27800, train loss: 10.305567741394043\n",
      "Epoch: 0, iter: 27900, train loss: 10.305180549621582\n",
      "Epoch: 0, iter: 28000, train loss: 10.305281639099121\n",
      "Epoch: 0, iter: 28100, train loss: 10.305341720581055\n",
      "Epoch: 0, iter: 28200, train loss: 10.305498123168945\n",
      "Epoch: 0, iter: 28300, train loss: 10.305514335632324\n",
      "Epoch: 0, iter: 28400, train loss: 10.30451774597168\n",
      "Epoch: 0, iter: 28500, train loss: 10.305739402770996\n",
      "Epoch: 0, iter: 28600, train loss: 10.305682182312012\n",
      "Epoch: 0, iter: 28700, train loss: 10.304980278015137\n",
      "Epoch: 0, iter: 28800, train loss: 10.306292533874512\n",
      "Epoch: 0, iter: 28900, train loss: 10.305081367492676\n",
      "Epoch: 0, iter: 29000, train loss: 10.30575942993164\n",
      "Epoch: 0, iter: 29100, train loss: 10.305368423461914\n",
      "Epoch: 0, iter: 29200, train loss: 10.305379867553711\n",
      "Epoch: 0, iter: 29300, train loss: 10.305133819580078\n",
      "Epoch: 0, iter: 29400, train loss: 10.304715156555176\n",
      "Epoch: 0, iter: 29500, train loss: 10.305133819580078\n",
      "Epoch: 0, iter: 29600, train loss: 10.305100440979004\n",
      "Epoch: 0, iter: 29700, train loss: 10.306047439575195\n",
      "Epoch: 0, iter: 29800, train loss: 10.305584907531738\n",
      "Epoch: 0, iter: 29900, train loss: 10.305647850036621\n",
      "Epoch: 0, iter: 30000, train loss: 10.30549430847168\n",
      "Epoch: 0, iter: 30100, train loss: 10.305641174316406\n",
      "Epoch: 0, iter: 30200, train loss: 10.305148124694824\n",
      "Epoch: 0, iter: 30300, train loss: 10.306059837341309\n",
      "Epoch: 0, iter: 30400, train loss: 10.305471420288086\n",
      "Epoch: 0, iter: 30500, train loss: 10.305829048156738\n",
      "Epoch: 0, iter: 30600, train loss: 10.305131912231445\n",
      "Epoch: 0, iter: 30700, train loss: 10.304669380187988\n",
      "Epoch: 0, iter: 30800, train loss: 10.306052207946777\n",
      "Epoch: 0, iter: 30900, train loss: 10.305885314941406\n",
      "Epoch: 0, iter: 31000, train loss: 10.304847717285156\n",
      "Epoch: 0, iter: 31100, train loss: 10.305349349975586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 31200, train loss: 10.305219650268555\n",
      "Epoch: 0, iter: 31300, train loss: 10.305341720581055\n",
      "Epoch: 0, iter: 31400, train loss: 10.305096626281738\n",
      "Epoch: 0, iter: 31500, train loss: 10.3058443069458\n",
      "Epoch: 0, iter: 31600, train loss: 10.304805755615234\n",
      "Epoch: 0, iter: 31700, train loss: 10.304418563842773\n",
      "Epoch: 0, iter: 31800, train loss: 10.304895401000977\n",
      "Epoch: 0, iter: 31900, train loss: 10.305886268615723\n",
      "Epoch: 0, iter: 32000, train loss: 10.304708480834961\n",
      "Epoch: 0, iter: 32100, train loss: 10.305288314819336\n",
      "Epoch: 0, iter: 32200, train loss: 10.305402755737305\n",
      "Epoch: 0, iter: 32300, train loss: 10.305286407470703\n",
      "Epoch: 0, iter: 32400, train loss: 10.305922508239746\n",
      "Epoch: 0, iter: 32500, train loss: 10.305919647216797\n",
      "Epoch: 0, iter: 32600, train loss: 10.304279327392578\n",
      "Epoch: 0, iter: 32700, train loss: 10.305517196655273\n",
      "Epoch: 0, iter: 32800, train loss: 10.305620193481445\n",
      "Epoch: 0, iter: 32900, train loss: 10.305193901062012\n",
      "Epoch: 0, iter: 33000, train loss: 10.305908203125\n",
      "Epoch: 0, iter: 33100, train loss: 10.305248260498047\n",
      "Epoch: 0, iter: 33200, train loss: 10.304734230041504\n",
      "Epoch: 0, iter: 33300, train loss: 10.304686546325684\n",
      "Epoch: 0, iter: 33400, train loss: 10.304969787597656\n",
      "Epoch: 0, iter: 33500, train loss: 10.306225776672363\n",
      "Epoch: 0, iter: 33600, train loss: 10.305286407470703\n",
      "Epoch: 0, iter: 33700, train loss: 10.305516242980957\n",
      "Epoch: 0, iter: 33800, train loss: 10.305280685424805\n",
      "Epoch: 0, iter: 33900, train loss: 10.304676055908203\n",
      "Epoch: 0, iter: 34000, train loss: 10.305549621582031\n",
      "Epoch: 0, iter: 34100, train loss: 10.305305480957031\n",
      "Epoch: 0, iter: 34200, train loss: 10.305797576904297\n",
      "Epoch: 0, iter: 34300, train loss: 10.305100440979004\n",
      "Epoch: 0, iter: 34400, train loss: 10.305152893066406\n",
      "Epoch: 0, iter: 34500, train loss: 10.305268287658691\n",
      "Epoch: 0, iter: 34600, train loss: 10.305633544921875\n",
      "Epoch: 0, iter: 34700, train loss: 10.304959297180176\n",
      "Epoch: 0, iter: 34800, train loss: 10.305944442749023\n",
      "Epoch: 0, iter: 34900, train loss: 10.306255340576172\n",
      "Epoch: 0, iter: 35000, train loss: 10.304973602294922\n",
      "Epoch: 0, iter: 35100, train loss: 10.306011199951172\n",
      "Epoch: 0, iter: 35200, train loss: 10.306090354919434\n",
      "Epoch: 0, iter: 35300, train loss: 10.306044578552246\n",
      "Epoch: 0, iter: 35400, train loss: 10.305774688720703\n",
      "Epoch: 0, iter: 35500, train loss: 10.30525016784668\n",
      "Epoch: 0, iter: 35600, train loss: 10.304917335510254\n",
      "Epoch: 0, iter: 35700, train loss: 10.304062843322754\n",
      "Epoch: 0, iter: 35800, train loss: 10.305028915405273\n",
      "Epoch: 0, iter: 35900, train loss: 10.3053617477417\n",
      "Epoch: 0, iter: 36000, train loss: 10.305822372436523\n",
      "Epoch: 0, iter: 36100, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 36200, train loss: 10.30526351928711\n",
      "Epoch: 0, iter: 36300, train loss: 10.30550765991211\n",
      "Epoch: 0, iter: 36400, train loss: 10.305481910705566\n",
      "Epoch: 0, iter: 36500, train loss: 10.305776596069336\n",
      "Epoch: 0, iter: 36600, train loss: 10.305306434631348\n",
      "Epoch: 0, iter: 36700, train loss: 10.306004524230957\n",
      "Epoch: 0, iter: 36800, train loss: 10.305416107177734\n",
      "Epoch: 0, iter: 36900, train loss: 10.305654525756836\n",
      "Epoch: 0, iter: 37000, train loss: 10.305665016174316\n",
      "Epoch: 0, iter: 37100, train loss: 10.305294036865234\n",
      "Epoch: 0, iter: 37200, train loss: 10.305218696594238\n",
      "Epoch: 0, iter: 37300, train loss: 10.304512023925781\n",
      "Epoch: 0, iter: 37400, train loss: 10.305214881896973\n",
      "Epoch: 0, iter: 37500, train loss: 10.306255340576172\n",
      "Epoch: 0, iter: 37600, train loss: 10.305598258972168\n",
      "Epoch: 0, iter: 37700, train loss: 10.305577278137207\n",
      "Epoch: 0, iter: 37800, train loss: 10.305211067199707\n",
      "Epoch: 0, iter: 37900, train loss: 10.305444717407227\n",
      "Epoch: 0, iter: 38000, train loss: 10.305280685424805\n",
      "Epoch: 0, iter: 38100, train loss: 10.3057861328125\n",
      "Epoch: 0, iter: 38200, train loss: 10.30602741241455\n",
      "Epoch: 0, iter: 38300, train loss: 10.305655479431152\n",
      "Epoch: 0, iter: 38400, train loss: 10.30456829071045\n",
      "Epoch: 0, iter: 38500, train loss: 10.3056640625\n",
      "Epoch: 0, iter: 38600, train loss: 10.305947303771973\n",
      "Epoch: 0, iter: 38700, train loss: 10.305456161499023\n",
      "Epoch: 0, iter: 38800, train loss: 10.305708885192871\n",
      "Epoch: 0, iter: 38900, train loss: 10.305451393127441\n",
      "Epoch: 0, iter: 39000, train loss: 10.304163932800293\n",
      "Epoch: 0, iter: 39100, train loss: 10.305095672607422\n",
      "Epoch: 0, iter: 39200, train loss: 10.305582046508789\n",
      "Epoch: 0, iter: 39300, train loss: 10.304159164428711\n",
      "Epoch: 0, iter: 39400, train loss: 10.305733680725098\n",
      "Epoch: 0, iter: 39500, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 39600, train loss: 10.30588150024414\n",
      "Epoch: 0, iter: 39700, train loss: 10.305072784423828\n",
      "Epoch: 0, iter: 39800, train loss: 10.305708885192871\n",
      "Epoch: 0, iter: 39900, train loss: 10.305602073669434\n",
      "Epoch: 0, iter: 40000, train loss: 10.305530548095703\n",
      "Epoch: 0, iter: 40100, train loss: 10.305734634399414\n",
      "Epoch: 0, iter: 40200, train loss: 10.305264472961426\n",
      "Epoch: 0, iter: 40300, train loss: 10.305008888244629\n",
      "Epoch: 0, iter: 40400, train loss: 10.304963111877441\n",
      "Epoch: 0, iter: 40500, train loss: 10.305113792419434\n",
      "Epoch: 0, iter: 40600, train loss: 10.305130958557129\n",
      "Epoch: 0, iter: 40700, train loss: 10.305484771728516\n",
      "Epoch: 0, iter: 40800, train loss: 10.305331230163574\n",
      "Epoch: 0, iter: 40900, train loss: 10.305100440979004\n",
      "Epoch: 0, iter: 41000, train loss: 10.305521011352539\n",
      "Epoch: 0, iter: 41100, train loss: 10.305133819580078\n",
      "Epoch: 0, iter: 41200, train loss: 10.30582046508789\n",
      "Epoch: 0, iter: 41300, train loss: 10.304549217224121\n",
      "Epoch: 0, iter: 41400, train loss: 10.305227279663086\n",
      "Epoch: 0, iter: 41500, train loss: 10.3057861328125\n",
      "Epoch: 0, iter: 41600, train loss: 10.305102348327637\n",
      "Epoch: 0, iter: 41700, train loss: 10.305768013000488\n",
      "Epoch: 0, iter: 41800, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 41900, train loss: 10.305428504943848\n",
      "Epoch: 0, iter: 42000, train loss: 10.3049955368042\n",
      "Epoch: 0, iter: 42100, train loss: 10.30445671081543\n",
      "Epoch: 0, iter: 42200, train loss: 10.305708885192871\n",
      "Epoch: 0, iter: 42300, train loss: 10.304706573486328\n",
      "Epoch: 0, iter: 42400, train loss: 10.305383682250977\n",
      "Epoch: 0, iter: 42500, train loss: 10.305912017822266\n",
      "Epoch: 0, iter: 42600, train loss: 10.305283546447754\n",
      "Epoch: 0, iter: 42700, train loss: 10.304912567138672\n",
      "Epoch: 0, iter: 42800, train loss: 10.304648399353027\n",
      "Epoch: 0, iter: 42900, train loss: 10.304394721984863\n",
      "Epoch: 0, iter: 43000, train loss: 10.304996490478516\n",
      "Epoch: 0, iter: 43100, train loss: 10.305522918701172\n",
      "Epoch: 0, iter: 43200, train loss: 10.305253982543945\n",
      "Epoch: 0, iter: 43300, train loss: 10.305895805358887\n",
      "Epoch: 0, iter: 43400, train loss: 10.305249214172363\n",
      "Epoch: 0, iter: 43500, train loss: 10.305253028869629\n",
      "Epoch: 0, iter: 43600, train loss: 10.304433822631836\n",
      "Epoch: 0, iter: 43700, train loss: 10.305436134338379\n",
      "Epoch: 0, iter: 43800, train loss: 10.305392265319824\n",
      "Epoch: 0, iter: 43900, train loss: 10.305694580078125\n",
      "Epoch: 0, iter: 44000, train loss: 10.305953025817871\n",
      "Epoch: 0, iter: 44100, train loss: 10.30540657043457\n",
      "Epoch: 0, iter: 44200, train loss: 10.305122375488281\n",
      "Epoch: 0, iter: 44300, train loss: 10.305431365966797\n",
      "Epoch: 0, iter: 44400, train loss: 10.30479621887207\n",
      "Epoch: 0, iter: 44500, train loss: 10.304688453674316\n",
      "Epoch: 0, iter: 44600, train loss: 10.305895805358887\n",
      "Epoch: 0, iter: 44700, train loss: 10.30532455444336\n",
      "Epoch: 0, iter: 44800, train loss: 10.305841445922852\n",
      "Epoch: 0, iter: 44900, train loss: 10.304998397827148\n",
      "Epoch: 0, iter: 45000, train loss: 10.30563735961914\n",
      "Epoch: 0, iter: 45100, train loss: 10.305000305175781\n",
      "Epoch: 0, iter: 45200, train loss: 10.3045072555542\n",
      "Epoch: 0, iter: 45300, train loss: 10.305994033813477\n",
      "Epoch: 0, iter: 45400, train loss: 10.304830551147461\n",
      "Epoch: 0, iter: 45500, train loss: 10.305908203125\n",
      "Epoch: 0, iter: 45600, train loss: 10.304892539978027\n",
      "Epoch: 0, iter: 45700, train loss: 10.305948257446289\n",
      "Epoch: 0, iter: 45800, train loss: 10.306305885314941\n",
      "Epoch: 0, iter: 45900, train loss: 10.305695533752441\n",
      "Epoch: 0, iter: 46000, train loss: 10.305947303771973\n",
      "Epoch: 0, iter: 46100, train loss: 10.305712699890137\n",
      "Epoch: 0, iter: 46200, train loss: 10.304917335510254\n",
      "Epoch: 0, iter: 46300, train loss: 10.305183410644531\n",
      "Epoch: 0, iter: 46400, train loss: 10.30496597290039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 46500, train loss: 10.304723739624023\n",
      "Epoch: 0, iter: 46600, train loss: 10.305729866027832\n",
      "Epoch: 0, iter: 46700, train loss: 10.30596923828125\n",
      "Epoch: 0, iter: 46800, train loss: 10.305035591125488\n",
      "Epoch: 0, iter: 46900, train loss: 10.304269790649414\n",
      "Epoch: 0, iter: 47000, train loss: 10.306767463684082\n",
      "Epoch: 0, iter: 47100, train loss: 10.305059432983398\n",
      "Epoch: 0, iter: 47200, train loss: 10.304559707641602\n",
      "Epoch: 0, iter: 47300, train loss: 10.305115699768066\n",
      "Epoch: 0, iter: 47400, train loss: 10.304896354675293\n",
      "Epoch: 0, iter: 47500, train loss: 10.305288314819336\n",
      "Epoch: 0, iter: 47600, train loss: 10.305190086364746\n",
      "Epoch: 0, iter: 47700, train loss: 10.304950714111328\n",
      "Epoch: 0, iter: 47800, train loss: 10.305194854736328\n",
      "Epoch: 0, iter: 47900, train loss: 10.305739402770996\n",
      "Epoch: 0, iter: 48000, train loss: 10.30505084991455\n",
      "Epoch: 0, iter: 48100, train loss: 10.304848670959473\n",
      "Epoch: 0, iter: 48200, train loss: 10.304980278015137\n",
      "Epoch: 0, iter: 48300, train loss: 10.305916786193848\n",
      "Epoch: 0, iter: 48400, train loss: 10.305719375610352\n",
      "Epoch: 0, iter: 48500, train loss: 10.305397033691406\n",
      "Epoch: 0, iter: 48600, train loss: 10.304701805114746\n",
      "Epoch: 0, iter: 48700, train loss: 10.304826736450195\n",
      "Epoch: 0, iter: 48800, train loss: 10.305529594421387\n",
      "Epoch: 0, iter: 48900, train loss: 10.305312156677246\n",
      "Epoch: 0, iter: 49000, train loss: 10.304925918579102\n",
      "Epoch: 0, iter: 49100, train loss: 10.305002212524414\n",
      "Epoch: 0, iter: 49200, train loss: 10.305131912231445\n",
      "Epoch: 0, iter: 49300, train loss: 10.30554485321045\n",
      "Epoch: 0, iter: 49400, train loss: 10.305079460144043\n",
      "Epoch: 0, iter: 49500, train loss: 10.305988311767578\n",
      "Epoch: 0, iter: 49600, train loss: 10.305246353149414\n",
      "Epoch: 0, iter: 49700, train loss: 10.306163787841797\n",
      "Epoch: 0, iter: 49800, train loss: 10.305546760559082\n",
      "Epoch: 0, iter: 49900, train loss: 10.305702209472656\n",
      "Epoch: 0, iter: 50000, train loss: 10.30470085144043\n",
      "Epoch: 0, iter: 50100, train loss: 10.304963111877441\n",
      "Epoch: 0, iter: 50200, train loss: 10.304985046386719\n",
      "Epoch: 0, iter: 50300, train loss: 10.306014060974121\n",
      "Epoch: 0, iter: 50400, train loss: 10.305625915527344\n",
      "Epoch: 0, iter: 50500, train loss: 10.305070877075195\n",
      "Epoch: 0, iter: 50600, train loss: 10.305132865905762\n",
      "Epoch: 0, iter: 50700, train loss: 10.304369926452637\n",
      "Epoch: 0, iter: 50800, train loss: 10.304798126220703\n",
      "Epoch: 0, iter: 50900, train loss: 10.304986953735352\n",
      "Epoch: 0, iter: 51000, train loss: 10.305133819580078\n",
      "Epoch: 0, iter: 51100, train loss: 10.305495262145996\n",
      "Epoch: 0, iter: 51200, train loss: 10.305096626281738\n",
      "Epoch: 0, iter: 51300, train loss: 10.305388450622559\n",
      "Epoch: 0, iter: 51400, train loss: 10.305380821228027\n",
      "Epoch: 0, iter: 51500, train loss: 10.304683685302734\n",
      "Epoch: 0, iter: 51600, train loss: 10.304330825805664\n",
      "Epoch: 0, iter: 51700, train loss: 10.305220603942871\n",
      "Epoch: 0, iter: 51800, train loss: 10.304788589477539\n",
      "Epoch: 0, iter: 51900, train loss: 10.304825782775879\n",
      "Epoch: 0, iter: 52000, train loss: 10.304912567138672\n",
      "Epoch: 0, iter: 52100, train loss: 10.305079460144043\n",
      "Epoch: 0, iter: 52200, train loss: 10.305645942687988\n",
      "Epoch: 0, iter: 52300, train loss: 10.304727554321289\n",
      "Epoch: 0, iter: 52400, train loss: 10.304756164550781\n",
      "Epoch: 0, iter: 52500, train loss: 10.305253028869629\n",
      "Epoch: 0, iter: 52600, train loss: 10.305310249328613\n",
      "Epoch: 0, iter: 52700, train loss: 10.305758476257324\n",
      "Epoch: 0, iter: 52800, train loss: 10.305388450622559\n",
      "Epoch: 0, iter: 52900, train loss: 10.30572509765625\n",
      "Epoch: 0, iter: 53000, train loss: 10.304509162902832\n",
      "Epoch: 0, iter: 53100, train loss: 10.305887222290039\n",
      "Epoch: 0, iter: 53200, train loss: 10.304953575134277\n",
      "Epoch: 0, iter: 53300, train loss: 10.305158615112305\n",
      "Epoch: 0, iter: 53400, train loss: 10.304776191711426\n",
      "Epoch: 0, iter: 53500, train loss: 10.305371284484863\n",
      "Epoch: 0, iter: 53600, train loss: 10.305889129638672\n",
      "Epoch: 0, iter: 53700, train loss: 10.305561065673828\n",
      "Epoch: 0, iter: 53800, train loss: 10.305675506591797\n",
      "Epoch: 0, iter: 53900, train loss: 10.30462646484375\n",
      "Epoch: 0, iter: 54000, train loss: 10.305017471313477\n",
      "Epoch: 0, iter: 54100, train loss: 10.305922508239746\n",
      "Epoch: 0, iter: 54200, train loss: 10.305235862731934\n",
      "Epoch: 0, iter: 54300, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 54400, train loss: 10.304987907409668\n",
      "Epoch: 0, iter: 54500, train loss: 10.304530143737793\n",
      "Epoch: 0, iter: 54600, train loss: 10.304821968078613\n",
      "Epoch: 0, iter: 54700, train loss: 10.304792404174805\n",
      "Epoch: 0, iter: 54800, train loss: 10.305532455444336\n",
      "Epoch: 0, iter: 54900, train loss: 10.305586814880371\n",
      "Epoch: 0, iter: 55000, train loss: 10.304991722106934\n",
      "Epoch: 0, iter: 55100, train loss: 10.305340766906738\n",
      "Epoch: 0, iter: 55200, train loss: 10.306321144104004\n",
      "Epoch: 0, iter: 55300, train loss: 10.305769920349121\n",
      "Epoch: 0, iter: 55400, train loss: 10.305258750915527\n",
      "Epoch: 0, iter: 55500, train loss: 10.305254936218262\n",
      "Epoch: 0, iter: 55600, train loss: 10.305436134338379\n",
      "Epoch: 0, iter: 55700, train loss: 10.30531120300293\n",
      "Epoch: 0, iter: 55800, train loss: 10.305092811584473\n",
      "Epoch: 0, iter: 55900, train loss: 10.305803298950195\n",
      "Epoch: 0, iter: 56000, train loss: 10.30581283569336\n",
      "Epoch: 0, iter: 56100, train loss: 10.305675506591797\n",
      "Epoch: 0, iter: 56200, train loss: 10.304985046386719\n",
      "Epoch: 0, iter: 56300, train loss: 10.305318832397461\n",
      "Epoch: 0, iter: 56400, train loss: 10.30487060546875\n",
      "Epoch: 0, iter: 56500, train loss: 10.305685997009277\n",
      "Epoch: 0, iter: 56600, train loss: 10.305030822753906\n",
      "Epoch: 0, iter: 56700, train loss: 10.304950714111328\n",
      "Epoch: 0, iter: 56800, train loss: 10.305856704711914\n",
      "Epoch: 0, iter: 56900, train loss: 10.305598258972168\n",
      "Epoch: 0, iter: 57000, train loss: 10.305926322937012\n",
      "Epoch: 0, iter: 57100, train loss: 10.305087089538574\n",
      "Epoch: 0, iter: 57200, train loss: 10.305057525634766\n",
      "Epoch: 0, iter: 57300, train loss: 10.305939674377441\n",
      "Epoch: 0, iter: 57400, train loss: 10.306361198425293\n",
      "Epoch: 0, iter: 57500, train loss: 10.305258750915527\n",
      "Epoch: 0, iter: 57600, train loss: 10.305447578430176\n",
      "Epoch: 0, iter: 57700, train loss: 10.30546760559082\n",
      "Epoch: 0, iter: 57800, train loss: 10.305329322814941\n",
      "Epoch: 0, iter: 57900, train loss: 10.306248664855957\n",
      "Epoch: 0, iter: 58000, train loss: 10.304973602294922\n",
      "Epoch: 0, iter: 58100, train loss: 10.305325508117676\n",
      "Epoch: 0, iter: 58200, train loss: 10.305733680725098\n",
      "Epoch: 0, iter: 58300, train loss: 10.305363655090332\n",
      "Epoch: 0, iter: 58400, train loss: 10.30481243133545\n",
      "Epoch: 0, iter: 58500, train loss: 10.304417610168457\n",
      "Epoch: 0, iter: 58600, train loss: 10.305554389953613\n",
      "Epoch: 0, iter: 58700, train loss: 10.305191993713379\n",
      "Epoch: 0, iter: 58800, train loss: 10.305366516113281\n",
      "Epoch: 0, iter: 58900, train loss: 10.305375099182129\n",
      "Epoch: 0, iter: 59000, train loss: 10.305258750915527\n",
      "Epoch: 0, iter: 59100, train loss: 10.30419635772705\n",
      "Epoch: 0, iter: 59200, train loss: 10.305328369140625\n",
      "Epoch: 0, iter: 59300, train loss: 10.305028915405273\n",
      "Epoch: 0, iter: 59400, train loss: 10.304783821105957\n",
      "Epoch: 0, iter: 59500, train loss: 10.30468463897705\n",
      "Epoch: 0, iter: 59600, train loss: 10.305556297302246\n",
      "Epoch: 0, iter: 59700, train loss: 10.304333686828613\n",
      "Epoch: 0, iter: 59800, train loss: 10.304949760437012\n",
      "Epoch: 0, iter: 59900, train loss: 10.304530143737793\n",
      "Epoch: 0, iter: 60000, train loss: 10.305764198303223\n",
      "Epoch: 0, iter: 60100, train loss: 10.305164337158203\n",
      "Epoch: 0, iter: 60200, train loss: 10.306214332580566\n",
      "Epoch: 0, iter: 60300, train loss: 10.304953575134277\n",
      "Epoch: 0, iter: 60400, train loss: 10.305407524108887\n",
      "Epoch: 0, iter: 60500, train loss: 10.305205345153809\n",
      "Epoch: 0, iter: 60600, train loss: 10.306256294250488\n",
      "Epoch: 0, iter: 60700, train loss: 10.30543327331543\n",
      "Epoch: 0, iter: 60800, train loss: 10.304978370666504\n",
      "Epoch: 0, iter: 60900, train loss: 10.305927276611328\n",
      "Epoch: 0, iter: 61000, train loss: 10.304603576660156\n",
      "Epoch: 0, iter: 61100, train loss: 10.305537223815918\n",
      "Epoch: 0, iter: 61200, train loss: 10.305209159851074\n",
      "Epoch: 0, iter: 61300, train loss: 10.304512977600098\n",
      "Epoch: 0, iter: 61400, train loss: 10.3048734664917\n",
      "Epoch: 0, iter: 61500, train loss: 10.304574966430664\n",
      "Epoch: 0, iter: 61600, train loss: 10.305403709411621\n",
      "Epoch: 0, iter: 61700, train loss: 10.305303573608398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 61800, train loss: 10.305171966552734\n",
      "Epoch: 0, iter: 61900, train loss: 10.306279182434082\n",
      "Epoch: 0, iter: 62000, train loss: 10.305185317993164\n",
      "Epoch: 0, iter: 62100, train loss: 10.305039405822754\n",
      "Epoch: 0, iter: 62200, train loss: 10.304617881774902\n",
      "Epoch: 0, iter: 62300, train loss: 10.305520057678223\n",
      "Epoch: 0, iter: 62400, train loss: 10.305477142333984\n",
      "Epoch: 0, iter: 62500, train loss: 10.305675506591797\n",
      "Epoch: 0, iter: 62600, train loss: 10.305644989013672\n",
      "Epoch: 0, iter: 62700, train loss: 10.305680274963379\n",
      "Epoch: 0, iter: 62800, train loss: 10.30467414855957\n",
      "Epoch: 0, iter: 62900, train loss: 10.305951118469238\n",
      "Epoch: 0, iter: 63000, train loss: 10.305655479431152\n",
      "Epoch: 0, iter: 63100, train loss: 10.305852890014648\n",
      "Epoch: 0, iter: 63200, train loss: 10.305624961853027\n",
      "Epoch: 0, iter: 63300, train loss: 10.305525779724121\n",
      "Epoch: 0, iter: 63400, train loss: 10.304691314697266\n",
      "Epoch: 0, iter: 63500, train loss: 10.304559707641602\n",
      "Epoch: 0, iter: 63600, train loss: 10.304993629455566\n",
      "Epoch: 0, iter: 63700, train loss: 10.305534362792969\n",
      "Epoch: 0, iter: 63800, train loss: 10.305026054382324\n",
      "Epoch: 0, iter: 63900, train loss: 10.3067045211792\n",
      "Epoch: 0, iter: 64000, train loss: 10.305097579956055\n",
      "Epoch: 0, iter: 64100, train loss: 10.305780410766602\n",
      "Epoch: 0, iter: 64200, train loss: 10.3049898147583\n",
      "Epoch: 0, iter: 64300, train loss: 10.305105209350586\n",
      "Epoch: 0, iter: 64400, train loss: 10.30491828918457\n",
      "Epoch: 0, iter: 64500, train loss: 10.304596900939941\n",
      "Epoch: 0, iter: 64600, train loss: 10.306053161621094\n",
      "Epoch: 0, iter: 64700, train loss: 10.304715156555176\n",
      "Epoch: 0, iter: 64800, train loss: 10.305985450744629\n",
      "Epoch: 0, iter: 64900, train loss: 10.305498123168945\n",
      "Epoch: 0, iter: 65000, train loss: 10.30456256866455\n",
      "Epoch: 0, iter: 65100, train loss: 10.305868148803711\n",
      "Epoch: 0, iter: 65200, train loss: 10.304875373840332\n",
      "Epoch: 0, iter: 65300, train loss: 10.305702209472656\n",
      "Epoch: 0, iter: 65400, train loss: 10.30522346496582\n",
      "Epoch: 0, iter: 65500, train loss: 10.305233001708984\n",
      "Epoch: 0, iter: 65600, train loss: 10.30461311340332\n",
      "Epoch: 0, iter: 65700, train loss: 10.305688858032227\n",
      "Epoch: 0, iter: 65800, train loss: 10.305314064025879\n",
      "Epoch: 0, iter: 65900, train loss: 10.304835319519043\n",
      "Epoch: 0, iter: 66000, train loss: 10.305259704589844\n",
      "Epoch: 0, iter: 66100, train loss: 10.304290771484375\n",
      "Epoch: 0, iter: 66200, train loss: 10.306077003479004\n",
      "Epoch: 0, iter: 66300, train loss: 10.304835319519043\n",
      "Epoch: 0, iter: 66400, train loss: 10.305837631225586\n",
      "Epoch: 0, iter: 66500, train loss: 10.3056001663208\n",
      "Epoch: 0, iter: 66600, train loss: 10.304738998413086\n",
      "Epoch: 0, iter: 66700, train loss: 10.305767059326172\n",
      "Epoch: 0, iter: 66800, train loss: 10.305461883544922\n",
      "Epoch: 0, iter: 66900, train loss: 10.304880142211914\n",
      "Epoch: 0, iter: 67000, train loss: 10.30489730834961\n",
      "Epoch: 0, iter: 67100, train loss: 10.304912567138672\n",
      "Epoch: 0, iter: 67200, train loss: 10.305032730102539\n",
      "Epoch: 0, iter: 67300, train loss: 10.304875373840332\n",
      "Epoch: 0, iter: 67400, train loss: 10.30510139465332\n",
      "Epoch: 0, iter: 67500, train loss: 10.305275917053223\n",
      "Epoch: 0, iter: 67600, train loss: 10.305386543273926\n",
      "Epoch: 0, iter: 67700, train loss: 10.30532455444336\n",
      "Epoch: 0, iter: 67800, train loss: 10.305261611938477\n",
      "Epoch: 0, iter: 67900, train loss: 10.305998802185059\n",
      "Epoch: 0, iter: 68000, train loss: 10.304610252380371\n",
      "Epoch: 0, iter: 68100, train loss: 10.30492877960205\n",
      "Epoch: 0, iter: 68200, train loss: 10.305290222167969\n",
      "Epoch: 0, iter: 68300, train loss: 10.304783821105957\n",
      "Epoch: 0, iter: 68400, train loss: 10.3059663772583\n",
      "Epoch: 0, iter: 68500, train loss: 10.305948257446289\n",
      "Epoch: 0, iter: 68600, train loss: 10.304875373840332\n",
      "Epoch: 0, iter: 68700, train loss: 10.3048734664917\n",
      "Epoch: 0, iter: 68800, train loss: 10.305716514587402\n",
      "Epoch: 0, iter: 68900, train loss: 10.305463790893555\n",
      "Epoch: 0, iter: 69000, train loss: 10.305072784423828\n",
      "Epoch: 0, iter: 69100, train loss: 10.306105613708496\n",
      "Epoch: 0, iter: 69200, train loss: 10.305933952331543\n",
      "Epoch: 0, iter: 69300, train loss: 10.305730819702148\n",
      "Epoch: 0, iter: 69400, train loss: 10.305318832397461\n",
      "Epoch: 0, iter: 69500, train loss: 10.304924011230469\n",
      "Epoch: 0, iter: 69600, train loss: 10.304898262023926\n",
      "Epoch: 0, iter: 69700, train loss: 10.305749893188477\n",
      "Epoch: 0, iter: 69800, train loss: 10.304644584655762\n",
      "Epoch: 0, iter: 69900, train loss: 10.305832862854004\n",
      "Epoch: 0, iter: 70000, train loss: 10.305797576904297\n",
      "Epoch: 0, iter: 70100, train loss: 10.304708480834961\n",
      "Epoch: 0, iter: 70200, train loss: 10.305063247680664\n",
      "Epoch: 0, iter: 70300, train loss: 10.305367469787598\n",
      "Epoch: 0, iter: 70400, train loss: 10.30554485321045\n",
      "Epoch: 0, iter: 70500, train loss: 10.304571151733398\n",
      "Epoch: 0, iter: 70600, train loss: 10.305694580078125\n",
      "Epoch: 0, iter: 70700, train loss: 10.305562973022461\n",
      "Epoch: 0, iter: 70800, train loss: 10.305577278137207\n",
      "Epoch: 0, iter: 70900, train loss: 10.305071830749512\n",
      "Epoch: 0, iter: 71000, train loss: 10.305634498596191\n",
      "Epoch: 0, iter: 71100, train loss: 10.304753303527832\n",
      "Epoch: 0, iter: 71200, train loss: 10.306230545043945\n",
      "Epoch: 0, iter: 71300, train loss: 10.305554389953613\n",
      "Epoch: 0, iter: 71400, train loss: 10.304774284362793\n",
      "Epoch: 0, iter: 71500, train loss: 10.305665016174316\n",
      "Epoch: 0, iter: 71600, train loss: 10.304350852966309\n",
      "Epoch: 0, iter: 71700, train loss: 10.305501937866211\n",
      "Epoch: 0, iter: 71800, train loss: 10.305337905883789\n",
      "Epoch: 0, iter: 71900, train loss: 10.305371284484863\n",
      "Epoch: 0, iter: 72000, train loss: 10.305209159851074\n",
      "Epoch: 0, iter: 72100, train loss: 10.306388854980469\n",
      "Epoch: 0, iter: 72200, train loss: 10.304774284362793\n",
      "Epoch: 0, iter: 72300, train loss: 10.306087493896484\n",
      "Epoch: 0, iter: 72400, train loss: 10.304832458496094\n",
      "Epoch: 0, iter: 72500, train loss: 10.304708480834961\n",
      "Epoch: 0, iter: 72600, train loss: 10.305441856384277\n",
      "Epoch: 0, iter: 72700, train loss: 10.3056640625\n",
      "Epoch: 0, iter: 72800, train loss: 10.306116104125977\n",
      "Epoch: 0, iter: 72900, train loss: 10.305776596069336\n",
      "Epoch: 0, iter: 73000, train loss: 10.305018424987793\n",
      "Epoch: 0, iter: 73100, train loss: 10.304795265197754\n",
      "Epoch: 0, iter: 73200, train loss: 10.305261611938477\n",
      "Epoch: 0, iter: 73300, train loss: 10.305556297302246\n",
      "Epoch: 0, iter: 73400, train loss: 10.305001258850098\n",
      "Epoch: 0, iter: 73500, train loss: 10.305008888244629\n",
      "Epoch: 0, iter: 73600, train loss: 10.305181503295898\n",
      "Epoch: 0, iter: 73700, train loss: 10.305315971374512\n",
      "Epoch: 0, iter: 73800, train loss: 10.305985450744629\n",
      "Epoch: 0, iter: 73900, train loss: 10.304553985595703\n",
      "Epoch: 0, iter: 74000, train loss: 10.30553913116455\n",
      "Epoch: 0, iter: 74100, train loss: 10.305146217346191\n",
      "Epoch: 0, iter: 74200, train loss: 10.305926322937012\n",
      "Epoch: 0, iter: 74300, train loss: 10.305828094482422\n",
      "Epoch: 0, iter: 74400, train loss: 10.304516792297363\n",
      "Epoch: 0, iter: 74500, train loss: 10.305870056152344\n",
      "Epoch: 0, iter: 74600, train loss: 10.306108474731445\n",
      "Epoch: 0, iter: 74700, train loss: 10.305747032165527\n",
      "Epoch: 0, iter: 74800, train loss: 10.305405616760254\n",
      "Epoch: 0, iter: 74900, train loss: 10.305200576782227\n",
      "Epoch: 0, iter: 75000, train loss: 10.304697036743164\n",
      "Epoch: 0, iter: 75100, train loss: 10.30496597290039\n",
      "Epoch: 0, iter: 75200, train loss: 10.305179595947266\n",
      "Epoch: 0, iter: 75300, train loss: 10.305048942565918\n",
      "Epoch: 0, iter: 75400, train loss: 10.30569076538086\n",
      "Epoch: 0, iter: 75500, train loss: 10.305268287658691\n",
      "Epoch: 0, iter: 75600, train loss: 10.305179595947266\n",
      "Epoch: 0, iter: 75700, train loss: 10.306004524230957\n",
      "Epoch: 0, iter: 75800, train loss: 10.304974555969238\n",
      "Epoch: 0, iter: 75900, train loss: 10.304659843444824\n",
      "Epoch: 0, iter: 76000, train loss: 10.305105209350586\n",
      "Epoch: 0, iter: 76100, train loss: 10.305469512939453\n",
      "Epoch: 0, iter: 76200, train loss: 10.305978775024414\n",
      "Epoch: 0, iter: 76300, train loss: 10.304961204528809\n",
      "Epoch: 0, iter: 76400, train loss: 10.305329322814941\n",
      "Epoch: 0, iter: 76500, train loss: 10.305456161499023\n",
      "Epoch: 0, iter: 76600, train loss: 10.304986953735352\n",
      "Epoch: 0, iter: 76700, train loss: 10.305455207824707\n",
      "Epoch: 0, iter: 76800, train loss: 10.305624961853027\n",
      "Epoch: 0, iter: 76900, train loss: 10.304823875427246\n",
      "Epoch: 0, iter: 77000, train loss: 10.305636405944824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 77100, train loss: 10.305015563964844\n",
      "Epoch: 0, iter: 77200, train loss: 10.305170059204102\n",
      "Epoch: 0, iter: 77300, train loss: 10.304656028747559\n",
      "Epoch: 0, iter: 77400, train loss: 10.3049955368042\n",
      "Epoch: 0, iter: 77500, train loss: 10.306097030639648\n",
      "Epoch: 0, iter: 77600, train loss: 10.305622100830078\n",
      "Epoch: 0, iter: 77700, train loss: 10.305209159851074\n",
      "Epoch: 0, iter: 77800, train loss: 10.304821968078613\n",
      "Epoch: 0, iter: 77900, train loss: 10.305119514465332\n",
      "Epoch: 0, iter: 78000, train loss: 10.304692268371582\n",
      "Epoch: 0, iter: 78100, train loss: 10.306661605834961\n",
      "Epoch: 0, iter: 78200, train loss: 10.305310249328613\n",
      "Epoch: 0, iter: 78300, train loss: 10.304648399353027\n",
      "Epoch: 0, iter: 78400, train loss: 10.305821418762207\n",
      "Epoch: 0, iter: 78500, train loss: 10.305100440979004\n",
      "Epoch: 0, iter: 78600, train loss: 10.30553913116455\n",
      "Epoch: 0, iter: 78700, train loss: 10.305062294006348\n",
      "Epoch: 0, iter: 78800, train loss: 10.304965019226074\n",
      "Epoch: 0, iter: 78900, train loss: 10.30588150024414\n",
      "Epoch: 0, iter: 79000, train loss: 10.304430961608887\n",
      "Epoch: 0, iter: 79100, train loss: 10.305395126342773\n",
      "Epoch: 0, iter: 79200, train loss: 10.305669784545898\n",
      "Epoch: 0, iter: 79300, train loss: 10.305419921875\n",
      "Epoch: 0, iter: 79400, train loss: 10.304987907409668\n",
      "Epoch: 0, iter: 79500, train loss: 10.305209159851074\n",
      "Epoch: 0, iter: 79600, train loss: 10.305471420288086\n",
      "Epoch: 0, iter: 79700, train loss: 10.304642677307129\n",
      "Epoch: 0, iter: 79800, train loss: 10.305588722229004\n",
      "Epoch: 0, iter: 79900, train loss: 10.304596900939941\n",
      "Epoch: 0, iter: 80000, train loss: 10.304892539978027\n",
      "Epoch: 0, iter: 80100, train loss: 10.305127143859863\n",
      "Epoch: 0, iter: 80200, train loss: 10.305201530456543\n",
      "Epoch: 0, iter: 80300, train loss: 10.305293083190918\n",
      "Epoch: 0, iter: 80400, train loss: 10.305517196655273\n",
      "Epoch: 0, iter: 80500, train loss: 10.305146217346191\n",
      "Epoch: 0, iter: 80600, train loss: 10.305346488952637\n",
      "Epoch: 0, iter: 80700, train loss: 10.30540657043457\n",
      "Epoch: 0, iter: 80800, train loss: 10.30500602722168\n",
      "Epoch: 0, iter: 80900, train loss: 10.305480003356934\n",
      "Epoch: 0, iter: 81000, train loss: 10.304940223693848\n",
      "Epoch: 0, iter: 81100, train loss: 10.305363655090332\n",
      "Epoch: 0, iter: 81200, train loss: 10.304783821105957\n",
      "Epoch: 0, iter: 81300, train loss: 10.305323600769043\n",
      "Epoch: 0, iter: 81400, train loss: 10.30555534362793\n",
      "Epoch: 0, iter: 81500, train loss: 10.306321144104004\n",
      "Epoch: 0, iter: 81600, train loss: 10.305809020996094\n",
      "Epoch: 0, iter: 81700, train loss: 10.305427551269531\n",
      "Epoch: 0, iter: 81800, train loss: 10.305678367614746\n",
      "Epoch: 0, iter: 81900, train loss: 10.305841445922852\n",
      "Epoch: 0, iter: 82000, train loss: 10.305438041687012\n",
      "Epoch: 0, iter: 82100, train loss: 10.305810928344727\n",
      "Epoch: 0, iter: 82200, train loss: 10.30558967590332\n",
      "Epoch: 0, iter: 82300, train loss: 10.304965019226074\n",
      "Epoch: 0, iter: 82400, train loss: 10.3048677444458\n",
      "Epoch: 0, iter: 82500, train loss: 10.305102348327637\n",
      "Epoch: 0, iter: 82600, train loss: 10.3046293258667\n",
      "Epoch: 0, iter: 82700, train loss: 10.306264877319336\n",
      "Epoch: 0, iter: 82800, train loss: 10.305968284606934\n",
      "Epoch: 0, iter: 82900, train loss: 10.305183410644531\n",
      "Epoch: 0, iter: 83000, train loss: 10.305105209350586\n",
      "Epoch: 0, iter: 83100, train loss: 10.305408477783203\n",
      "Epoch: 0, iter: 83200, train loss: 10.305558204650879\n",
      "Epoch: 0, iter: 83300, train loss: 10.304647445678711\n",
      "Epoch: 0, iter: 83400, train loss: 10.305180549621582\n",
      "Epoch: 0, iter: 83500, train loss: 10.305819511413574\n",
      "Epoch: 0, iter: 83600, train loss: 10.305217742919922\n",
      "Epoch: 0, iter: 83700, train loss: 10.305289268493652\n",
      "Epoch: 0, iter: 83800, train loss: 10.305428504943848\n",
      "Epoch: 0, iter: 83900, train loss: 10.305941581726074\n",
      "Epoch: 0, iter: 84000, train loss: 10.305841445922852\n",
      "Epoch: 0, iter: 84100, train loss: 10.305018424987793\n",
      "Epoch: 0, iter: 84200, train loss: 10.304163932800293\n",
      "Epoch: 0, iter: 84300, train loss: 10.305573463439941\n",
      "Epoch: 0, iter: 84400, train loss: 10.305444717407227\n",
      "Epoch: 0, iter: 84500, train loss: 10.305098533630371\n",
      "Epoch: 0, iter: 84600, train loss: 10.305702209472656\n",
      "Epoch: 0, iter: 84700, train loss: 10.305272102355957\n",
      "Epoch: 0, iter: 84800, train loss: 10.305541038513184\n",
      "Epoch: 0, iter: 84900, train loss: 10.306105613708496\n",
      "Epoch: 0, iter: 85000, train loss: 10.304627418518066\n",
      "Epoch: 0, iter: 85100, train loss: 10.304631233215332\n",
      "Epoch: 0, iter: 85200, train loss: 10.305145263671875\n",
      "Epoch: 0, iter: 85300, train loss: 10.305259704589844\n",
      "Epoch: 0, iter: 85400, train loss: 10.306602478027344\n",
      "Epoch: 0, iter: 85500, train loss: 10.305480003356934\n",
      "Epoch: 0, iter: 85600, train loss: 10.305937767028809\n",
      "Epoch: 0, iter: 85700, train loss: 10.30573844909668\n",
      "Epoch: 0, iter: 85800, train loss: 10.305089950561523\n",
      "Epoch: 0, iter: 85900, train loss: 10.304880142211914\n",
      "Epoch: 0, iter: 86000, train loss: 10.30575180053711\n",
      "Epoch: 0, iter: 86100, train loss: 10.305466651916504\n",
      "Epoch: 0, iter: 86200, train loss: 10.306097030639648\n",
      "Epoch: 0, iter: 86300, train loss: 10.305519104003906\n",
      "Epoch: 0, iter: 86400, train loss: 10.30484390258789\n",
      "Epoch: 0, iter: 86500, train loss: 10.305054664611816\n",
      "Epoch: 0, iter: 86600, train loss: 10.3052396774292\n",
      "Epoch: 0, iter: 86700, train loss: 10.304488182067871\n",
      "Epoch: 0, iter: 86800, train loss: 10.3043851852417\n",
      "Epoch: 0, iter: 86900, train loss: 10.305144309997559\n",
      "Epoch: 0, iter: 87000, train loss: 10.304747581481934\n",
      "Epoch: 0, iter: 87100, train loss: 10.304476737976074\n",
      "Epoch: 0, iter: 87200, train loss: 10.304708480834961\n",
      "Epoch: 0, iter: 87300, train loss: 10.305715560913086\n",
      "Epoch: 0, iter: 87400, train loss: 10.305201530456543\n",
      "Epoch: 0, iter: 87500, train loss: 10.304478645324707\n",
      "Epoch: 0, iter: 87600, train loss: 10.30462646484375\n",
      "Epoch: 0, iter: 87700, train loss: 10.3052978515625\n",
      "Epoch: 0, iter: 87800, train loss: 10.305652618408203\n",
      "Epoch: 0, iter: 87900, train loss: 10.305375099182129\n",
      "Epoch: 0, iter: 88000, train loss: 10.305456161499023\n",
      "Epoch: 0, iter: 88100, train loss: 10.3056640625\n",
      "Epoch: 0, iter: 88200, train loss: 10.305551528930664\n",
      "Epoch: 0, iter: 88300, train loss: 10.305423736572266\n",
      "Epoch: 0, iter: 88400, train loss: 10.306057929992676\n",
      "Epoch: 0, iter: 88500, train loss: 10.304439544677734\n",
      "Epoch: 0, iter: 88600, train loss: 10.305453300476074\n",
      "Epoch: 0, iter: 88700, train loss: 10.304078102111816\n",
      "Epoch: 0, iter: 88800, train loss: 10.30594253540039\n",
      "Epoch: 0, iter: 88900, train loss: 10.305463790893555\n",
      "Epoch: 0, iter: 89000, train loss: 10.305809020996094\n",
      "Epoch: 0, iter: 89100, train loss: 10.305074691772461\n",
      "Epoch: 0, iter: 89200, train loss: 10.305458068847656\n",
      "Epoch: 0, iter: 89300, train loss: 10.30531120300293\n",
      "Epoch: 0, iter: 89400, train loss: 10.306329727172852\n",
      "Epoch: 0, iter: 89500, train loss: 10.305185317993164\n",
      "Epoch: 0, iter: 89600, train loss: 10.30508804321289\n",
      "Epoch: 0, iter: 89700, train loss: 10.305682182312012\n",
      "Epoch: 0, iter: 89800, train loss: 10.305944442749023\n",
      "Epoch: 0, iter: 89900, train loss: 10.304841041564941\n",
      "Epoch: 0, iter: 90000, train loss: 10.305569648742676\n",
      "Epoch: 0, iter: 90100, train loss: 10.305217742919922\n",
      "Epoch: 0, iter: 90200, train loss: 10.304976463317871\n",
      "Epoch: 0, iter: 90300, train loss: 10.305930137634277\n",
      "Epoch: 0, iter: 90400, train loss: 10.304834365844727\n",
      "Epoch: 0, iter: 90500, train loss: 10.304365158081055\n",
      "Epoch: 0, iter: 90600, train loss: 10.3051118850708\n",
      "Epoch: 0, iter: 90700, train loss: 10.304666519165039\n",
      "Epoch: 0, iter: 90800, train loss: 10.305706024169922\n",
      "Epoch: 0, iter: 90900, train loss: 10.305000305175781\n",
      "Epoch: 0, iter: 91000, train loss: 10.304915428161621\n",
      "Epoch: 0, iter: 91100, train loss: 10.305337905883789\n",
      "Epoch: 0, iter: 91200, train loss: 10.305373191833496\n",
      "Epoch: 0, iter: 91300, train loss: 10.305754661560059\n",
      "Epoch: 0, iter: 91400, train loss: 10.304686546325684\n",
      "Epoch: 0, iter: 91500, train loss: 10.305408477783203\n",
      "Epoch: 0, iter: 91600, train loss: 10.305493354797363\n",
      "Epoch: 0, iter: 91700, train loss: 10.305498123168945\n",
      "Epoch: 0, iter: 91800, train loss: 10.305305480957031\n",
      "Epoch: 0, iter: 91900, train loss: 10.305615425109863\n",
      "Epoch: 0, iter: 92000, train loss: 10.305686950683594\n",
      "Epoch: 0, iter: 92100, train loss: 10.305617332458496\n",
      "Epoch: 0, iter: 92200, train loss: 10.305350303649902\n",
      "Epoch: 0, iter: 92300, train loss: 10.305578231811523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 92400, train loss: 10.305139541625977\n",
      "Epoch: 0, iter: 92500, train loss: 10.305498123168945\n",
      "Epoch: 0, iter: 92600, train loss: 10.306621551513672\n",
      "Epoch: 0, iter: 92700, train loss: 10.30533218383789\n",
      "Epoch: 0, iter: 92800, train loss: 10.305970191955566\n",
      "Epoch: 0, iter: 92900, train loss: 10.305500030517578\n",
      "Epoch: 0, iter: 93000, train loss: 10.305643081665039\n",
      "Epoch: 0, iter: 93100, train loss: 10.305586814880371\n",
      "Epoch: 0, iter: 93200, train loss: 10.305874824523926\n",
      "Epoch: 0, iter: 93300, train loss: 10.30545425415039\n",
      "Epoch: 0, iter: 93400, train loss: 10.304940223693848\n",
      "Epoch: 0, iter: 93500, train loss: 10.305245399475098\n",
      "Epoch: 0, iter: 93600, train loss: 10.305953025817871\n",
      "Epoch: 0, iter: 93700, train loss: 10.305839538574219\n",
      "Epoch: 0, iter: 93800, train loss: 10.305904388427734\n",
      "Epoch: 0, iter: 93900, train loss: 10.305938720703125\n",
      "Epoch: 0, iter: 94000, train loss: 10.305733680725098\n",
      "Epoch: 0, iter: 94100, train loss: 10.305489540100098\n",
      "Epoch: 0, iter: 94200, train loss: 10.305126190185547\n",
      "Epoch: 0, iter: 94300, train loss: 10.304731369018555\n",
      "Epoch: 0, iter: 94400, train loss: 10.305595397949219\n",
      "Epoch: 0, iter: 94500, train loss: 10.3052978515625\n",
      "Epoch: 0, iter: 94600, train loss: 10.3058443069458\n",
      "Epoch: 0, iter: 94700, train loss: 10.305826187133789\n",
      "Epoch: 0, iter: 94800, train loss: 10.305288314819336\n",
      "Epoch: 0, iter: 94900, train loss: 10.305741310119629\n",
      "Epoch: 0, iter: 95000, train loss: 10.304913520812988\n",
      "Epoch: 0, iter: 95100, train loss: 10.306256294250488\n",
      "Epoch: 0, iter: 95200, train loss: 10.305420875549316\n",
      "Epoch: 0, iter: 95300, train loss: 10.304471015930176\n",
      "Epoch: 0, iter: 95400, train loss: 10.306279182434082\n",
      "Epoch: 0, iter: 95500, train loss: 10.305274963378906\n",
      "Epoch: 0, iter: 95600, train loss: 10.305185317993164\n",
      "Epoch: 0, iter: 95700, train loss: 10.304731369018555\n",
      "Epoch: 0, iter: 95800, train loss: 10.304715156555176\n",
      "Epoch: 0, iter: 95900, train loss: 10.304900169372559\n",
      "Epoch: 0, iter: 96000, train loss: 10.305144309997559\n",
      "Epoch: 0, iter: 96100, train loss: 10.30526351928711\n",
      "Epoch: 0, iter: 96200, train loss: 10.30545425415039\n",
      "Epoch: 0, iter: 96300, train loss: 10.306246757507324\n",
      "Epoch: 0, iter: 96400, train loss: 10.304605484008789\n",
      "Epoch: 0, iter: 96500, train loss: 10.305891036987305\n",
      "Epoch: 0, iter: 96600, train loss: 10.30592155456543\n",
      "Epoch: 0, iter: 96700, train loss: 10.304204940795898\n",
      "Epoch: 0, iter: 96800, train loss: 10.306077003479004\n",
      "Epoch: 0, iter: 96900, train loss: 10.305553436279297\n",
      "Epoch: 0, iter: 97000, train loss: 10.3052396774292\n",
      "Epoch: 0, iter: 97100, train loss: 10.30523681640625\n",
      "Epoch: 0, iter: 97200, train loss: 10.305159568786621\n",
      "Epoch: 0, iter: 97300, train loss: 10.305440902709961\n",
      "Epoch: 0, iter: 97400, train loss: 10.306550025939941\n",
      "Epoch: 0, iter: 97500, train loss: 10.305314064025879\n",
      "Epoch: 0, iter: 97600, train loss: 10.305624008178711\n",
      "Epoch: 0, iter: 97700, train loss: 10.305371284484863\n",
      "Epoch: 0, iter: 97800, train loss: 10.305495262145996\n",
      "Epoch: 0, iter: 97900, train loss: 10.305420875549316\n",
      "Epoch: 0, iter: 98000, train loss: 10.305257797241211\n",
      "Epoch: 0, iter: 98100, train loss: 10.3046293258667\n",
      "Epoch: 0, iter: 98200, train loss: 10.305278778076172\n",
      "Epoch: 0, iter: 98300, train loss: 10.305828094482422\n",
      "Epoch: 0, iter: 98400, train loss: 10.305078506469727\n",
      "Epoch: 0, iter: 98500, train loss: 10.305278778076172\n",
      "Epoch: 0, iter: 98600, train loss: 10.305079460144043\n",
      "Epoch: 0, iter: 98700, train loss: 10.305347442626953\n",
      "Epoch: 0, iter: 98800, train loss: 10.305449485778809\n",
      "Epoch: 0, iter: 98900, train loss: 10.305258750915527\n",
      "Epoch: 0, iter: 99000, train loss: 10.306678771972656\n",
      "Epoch: 0, iter: 99100, train loss: 10.30548095703125\n",
      "Epoch: 0, iter: 99200, train loss: 10.305582046508789\n",
      "Epoch: 0, iter: 99300, train loss: 10.305675506591797\n",
      "Epoch: 0, iter: 99400, train loss: 10.304496765136719\n",
      "Epoch: 0, iter: 99500, train loss: 10.304444313049316\n",
      "Epoch: 0, iter: 99600, train loss: 10.304939270019531\n",
      "Epoch: 0, iter: 99700, train loss: 10.305816650390625\n",
      "Epoch: 0, iter: 99800, train loss: 10.305434226989746\n",
      "Epoch: 0, iter: 99900, train loss: 10.30566692352295\n",
      "Epoch: 0, iter: 100000, train loss: 10.305647850036621\n",
      "Epoch: 0, iter: 100100, train loss: 10.306124687194824\n",
      "Epoch: 0, iter: 100200, train loss: 10.305171966552734\n",
      "Epoch: 0, iter: 100300, train loss: 10.305713653564453\n",
      "Epoch: 0, iter: 100400, train loss: 10.304957389831543\n",
      "Epoch: 0, iter: 100500, train loss: 10.306157112121582\n",
      "Epoch: 0, iter: 100600, train loss: 10.30523681640625\n",
      "Epoch: 0, iter: 100700, train loss: 10.305258750915527\n",
      "Epoch: 0, iter: 100800, train loss: 10.305503845214844\n",
      "Epoch: 0, iter: 100900, train loss: 10.30537223815918\n",
      "Epoch: 0, iter: 101000, train loss: 10.304864883422852\n",
      "Epoch: 0, iter: 101100, train loss: 10.305075645446777\n",
      "Epoch: 0, iter: 101200, train loss: 10.304609298706055\n",
      "Epoch: 0, iter: 101300, train loss: 10.305145263671875\n",
      "Epoch: 0, iter: 101400, train loss: 10.306243896484375\n",
      "Epoch: 0, iter: 101500, train loss: 10.305571556091309\n",
      "Epoch: 0, iter: 101600, train loss: 10.305059432983398\n",
      "Epoch: 0, iter: 101700, train loss: 10.305366516113281\n",
      "Epoch: 0, iter: 101800, train loss: 10.306009292602539\n",
      "Epoch: 0, iter: 101900, train loss: 10.305438041687012\n",
      "Epoch: 0, iter: 102000, train loss: 10.305251121520996\n",
      "Epoch: 0, iter: 102100, train loss: 10.30445671081543\n",
      "Epoch: 0, iter: 102200, train loss: 10.304801940917969\n",
      "Epoch: 0, iter: 102300, train loss: 10.305037498474121\n",
      "Epoch: 0, iter: 102400, train loss: 10.305383682250977\n",
      "Epoch: 0, iter: 102500, train loss: 10.305829048156738\n",
      "Epoch: 0, iter: 102600, train loss: 10.305769920349121\n",
      "Epoch: 0, iter: 102700, train loss: 10.305130958557129\n",
      "Epoch: 0, iter: 102800, train loss: 10.304841041564941\n",
      "Epoch: 0, iter: 102900, train loss: 10.305098533630371\n",
      "Epoch: 0, iter: 103000, train loss: 10.305123329162598\n",
      "Epoch: 0, iter: 103100, train loss: 10.305323600769043\n",
      "Epoch: 0, iter: 103200, train loss: 10.304718971252441\n",
      "Epoch: 0, iter: 103300, train loss: 10.305739402770996\n",
      "Epoch: 0, iter: 103400, train loss: 10.306042671203613\n",
      "Epoch: 0, iter: 103500, train loss: 10.306095123291016\n",
      "Epoch: 0, iter: 103600, train loss: 10.305778503417969\n",
      "Epoch: 0, iter: 103700, train loss: 10.305893898010254\n",
      "Epoch: 0, iter: 103800, train loss: 10.306199073791504\n",
      "Epoch: 0, iter: 103900, train loss: 10.305412292480469\n",
      "Epoch: 0, iter: 104000, train loss: 10.305398941040039\n",
      "Epoch: 0, iter: 104100, train loss: 10.30477523803711\n",
      "Epoch: 0, iter: 104200, train loss: 10.305563926696777\n",
      "Epoch: 0, iter: 104300, train loss: 10.304632186889648\n",
      "Epoch: 0, iter: 104400, train loss: 10.304551124572754\n",
      "Epoch: 0, iter: 104500, train loss: 10.305612564086914\n",
      "Epoch: 0, iter: 104600, train loss: 10.304825782775879\n",
      "Epoch: 0, iter: 104700, train loss: 10.305935859680176\n",
      "Epoch: 0, iter: 104800, train loss: 10.30517292022705\n",
      "Epoch: 0, iter: 104900, train loss: 10.305463790893555\n",
      "Epoch: 0, iter: 105000, train loss: 10.304720878601074\n",
      "Epoch: 0, iter: 105100, train loss: 10.305156707763672\n",
      "Epoch: 0, iter: 105200, train loss: 10.305237770080566\n",
      "Epoch: 0, iter: 105300, train loss: 10.305377006530762\n",
      "Epoch: 0, iter: 105400, train loss: 10.304819107055664\n",
      "Epoch: 0, iter: 105500, train loss: 10.305675506591797\n",
      "Epoch: 0, iter: 105600, train loss: 10.304194450378418\n",
      "Epoch: 0, iter: 105700, train loss: 10.305992126464844\n",
      "Epoch: 0, iter: 105800, train loss: 10.305315017700195\n",
      "Epoch: 0, iter: 105900, train loss: 10.304535865783691\n",
      "Epoch: 0, iter: 106000, train loss: 10.304848670959473\n",
      "Epoch: 0, iter: 106100, train loss: 10.304178237915039\n",
      "Epoch: 0, iter: 106200, train loss: 10.305519104003906\n",
      "Epoch: 0, iter: 106300, train loss: 10.305476188659668\n",
      "Epoch: 0, iter: 106400, train loss: 10.305765151977539\n",
      "Epoch: 0, iter: 106500, train loss: 10.305703163146973\n",
      "Epoch: 0, iter: 106600, train loss: 10.305270195007324\n",
      "Epoch: 0, iter: 106700, train loss: 10.304969787597656\n",
      "Epoch: 0, iter: 106800, train loss: 10.305334091186523\n",
      "Epoch: 0, iter: 106900, train loss: 10.304788589477539\n",
      "Epoch: 0, iter: 107000, train loss: 10.305501937866211\n",
      "Epoch: 0, iter: 107100, train loss: 10.305747985839844\n",
      "Epoch: 0, iter: 107200, train loss: 10.3058500289917\n",
      "Epoch: 0, iter: 107300, train loss: 10.305472373962402\n",
      "Epoch: 0, iter: 107400, train loss: 10.304814338684082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 107500, train loss: 10.305224418640137\n",
      "Epoch: 0, iter: 107600, train loss: 10.305394172668457\n",
      "Epoch: 0, iter: 107700, train loss: 10.305127143859863\n",
      "Epoch: 0, iter: 107800, train loss: 10.306052207946777\n",
      "Epoch: 0, iter: 107900, train loss: 10.30586051940918\n",
      "Epoch: 0, iter: 108000, train loss: 10.305109024047852\n",
      "Epoch: 0, iter: 108100, train loss: 10.305293083190918\n",
      "Epoch: 0, iter: 108200, train loss: 10.305773735046387\n",
      "Epoch: 0, iter: 108300, train loss: 10.30512809753418\n",
      "Epoch: 0, iter: 108400, train loss: 10.304883003234863\n",
      "Epoch: 0, iter: 108500, train loss: 10.305641174316406\n",
      "Epoch: 0, iter: 108600, train loss: 10.305787086486816\n",
      "Epoch: 0, iter: 108700, train loss: 10.30542278289795\n",
      "Epoch: 0, iter: 108800, train loss: 10.304143905639648\n",
      "Epoch: 0, iter: 108900, train loss: 10.305015563964844\n",
      "Epoch: 0, iter: 109000, train loss: 10.305386543273926\n",
      "Epoch: 0, iter: 109100, train loss: 10.305811882019043\n",
      "Epoch: 0, iter: 109200, train loss: 10.306024551391602\n",
      "Epoch: 0, iter: 109300, train loss: 10.305342674255371\n",
      "Epoch: 0, iter: 109400, train loss: 10.306013107299805\n",
      "Epoch: 0, iter: 109500, train loss: 10.305148124694824\n",
      "Epoch: 0, iter: 109600, train loss: 10.30539321899414\n",
      "Epoch: 0, iter: 109700, train loss: 10.304909706115723\n",
      "Epoch: 0, iter: 109800, train loss: 10.305349349975586\n",
      "Epoch: 0, iter: 109900, train loss: 10.304686546325684\n",
      "Epoch: 0, iter: 110000, train loss: 10.304866790771484\n",
      "Epoch: 0, iter: 110100, train loss: 10.305805206298828\n",
      "Epoch: 0, iter: 110200, train loss: 10.305627822875977\n",
      "Epoch: 0, iter: 110300, train loss: 10.305493354797363\n",
      "Epoch: 0, iter: 110400, train loss: 10.3056640625\n",
      "Epoch: 0, iter: 110500, train loss: 10.30499267578125\n",
      "Epoch: 0, iter: 110600, train loss: 10.305869102478027\n",
      "Epoch: 0, iter: 110700, train loss: 10.30605697631836\n",
      "Epoch: 0, iter: 110800, train loss: 10.304871559143066\n",
      "Epoch: 0, iter: 110900, train loss: 10.305512428283691\n",
      "Epoch: 0, iter: 111000, train loss: 10.305551528930664\n",
      "Epoch: 0, iter: 111100, train loss: 10.305464744567871\n",
      "Epoch: 0, iter: 111200, train loss: 10.30543327331543\n",
      "Epoch: 0, iter: 111300, train loss: 10.30435562133789\n",
      "Epoch: 0, iter: 111400, train loss: 10.305342674255371\n",
      "Epoch: 0, iter: 111500, train loss: 10.304936408996582\n",
      "Epoch: 0, iter: 111600, train loss: 10.304338455200195\n",
      "Epoch: 0, iter: 111700, train loss: 10.30553913116455\n",
      "Epoch: 0, iter: 111800, train loss: 10.305567741394043\n",
      "Epoch: 0, iter: 111900, train loss: 10.305049896240234\n",
      "Epoch: 0, iter: 112000, train loss: 10.304856300354004\n",
      "Epoch: 0, iter: 112100, train loss: 10.305242538452148\n",
      "Epoch: 0, iter: 112200, train loss: 10.304795265197754\n",
      "Epoch: 0, iter: 112300, train loss: 10.305514335632324\n",
      "Epoch: 0, iter: 112400, train loss: 10.30508041381836\n",
      "Epoch: 0, iter: 112500, train loss: 10.305523872375488\n",
      "Epoch: 0, iter: 112600, train loss: 10.305197715759277\n",
      "Epoch: 0, iter: 112700, train loss: 10.304418563842773\n",
      "Epoch: 0, iter: 112800, train loss: 10.304969787597656\n",
      "Epoch: 0, iter: 112900, train loss: 10.3055419921875\n",
      "Epoch: 0, iter: 113000, train loss: 10.305259704589844\n",
      "Epoch: 0, iter: 113100, train loss: 10.304274559020996\n",
      "Epoch: 0, iter: 113200, train loss: 10.305392265319824\n",
      "Epoch: 0, iter: 113300, train loss: 10.304634094238281\n",
      "Epoch: 0, iter: 113400, train loss: 10.305904388427734\n",
      "Epoch: 0, iter: 113500, train loss: 10.305449485778809\n",
      "Epoch: 0, iter: 113600, train loss: 10.304267883300781\n",
      "Epoch: 0, iter: 113700, train loss: 10.305633544921875\n",
      "Epoch: 0, iter: 113800, train loss: 10.305607795715332\n",
      "Epoch: 0, iter: 113900, train loss: 10.304937362670898\n",
      "Epoch: 0, iter: 114000, train loss: 10.305615425109863\n",
      "Epoch: 0, iter: 114100, train loss: 10.305156707763672\n",
      "Epoch: 0, iter: 114200, train loss: 10.304889678955078\n",
      "Epoch: 0, iter: 114300, train loss: 10.305414199829102\n",
      "Epoch: 0, iter: 114400, train loss: 10.304465293884277\n",
      "Epoch: 0, iter: 114500, train loss: 10.305200576782227\n",
      "Epoch: 0, iter: 114600, train loss: 10.305974006652832\n",
      "Epoch: 0, iter: 114700, train loss: 10.304692268371582\n",
      "Epoch: 0, iter: 114800, train loss: 10.306037902832031\n",
      "Epoch: 0, iter: 114900, train loss: 10.305298805236816\n",
      "Epoch: 0, iter: 115000, train loss: 10.305590629577637\n",
      "Epoch: 0, iter: 115100, train loss: 10.305028915405273\n",
      "Epoch: 0, iter: 115200, train loss: 10.305741310119629\n",
      "Epoch: 0, iter: 115300, train loss: 10.304699897766113\n",
      "Epoch: 0, iter: 115400, train loss: 10.305781364440918\n",
      "Epoch: 0, iter: 115500, train loss: 10.305941581726074\n",
      "Epoch: 0, iter: 115600, train loss: 10.305410385131836\n",
      "Epoch: 0, iter: 115700, train loss: 10.304527282714844\n",
      "Epoch: 0, iter: 115800, train loss: 10.304893493652344\n",
      "Epoch: 0, iter: 115900, train loss: 10.30483627319336\n",
      "Epoch: 0, iter: 116000, train loss: 10.306042671203613\n",
      "Epoch: 0, iter: 116100, train loss: 10.304880142211914\n",
      "Epoch: 0, iter: 116200, train loss: 10.306079864501953\n",
      "Epoch: 0, iter: 116300, train loss: 10.304973602294922\n",
      "Epoch: 0, iter: 116400, train loss: 10.304862976074219\n",
      "Epoch: 0, iter: 116500, train loss: 10.305084228515625\n",
      "Epoch: 0, iter: 116600, train loss: 10.305741310119629\n",
      "Epoch: 0, iter: 116700, train loss: 10.305092811584473\n",
      "Epoch: 0, iter: 116800, train loss: 10.305068016052246\n",
      "Epoch: 0, iter: 116900, train loss: 10.305672645568848\n",
      "Epoch: 0, iter: 117000, train loss: 10.305685997009277\n",
      "Epoch: 0, iter: 117100, train loss: 10.305431365966797\n",
      "Epoch: 0, iter: 117200, train loss: 10.305034637451172\n",
      "Epoch: 0, iter: 117300, train loss: 10.304076194763184\n",
      "Epoch: 0, iter: 117400, train loss: 10.304917335510254\n",
      "Epoch: 0, iter: 117500, train loss: 10.306449890136719\n",
      "Epoch: 0, iter: 117600, train loss: 10.304600715637207\n",
      "Epoch: 0, iter: 117700, train loss: 10.305407524108887\n",
      "Epoch: 0, iter: 117800, train loss: 10.304718971252441\n",
      "Epoch: 0, iter: 117900, train loss: 10.304875373840332\n",
      "Epoch: 0, iter: 118000, train loss: 10.304615020751953\n",
      "Epoch: 0, iter: 118100, train loss: 10.305603981018066\n",
      "Epoch: 0, iter: 118200, train loss: 10.305318832397461\n",
      "Epoch: 0, iter: 118300, train loss: 10.305952072143555\n",
      "Epoch: 0, iter: 118400, train loss: 10.305390357971191\n",
      "Epoch: 0, iter: 118500, train loss: 10.305523872375488\n",
      "Epoch: 0, iter: 118600, train loss: 10.305353164672852\n",
      "Epoch: 0, iter: 118700, train loss: 10.3057861328125\n",
      "Epoch: 0, iter: 118800, train loss: 10.305158615112305\n",
      "Epoch: 0, iter: 118900, train loss: 10.304941177368164\n",
      "Epoch: 0, iter: 119000, train loss: 10.305932998657227\n",
      "Epoch: 0, iter: 119100, train loss: 10.305296897888184\n",
      "Epoch: 0, iter: 119200, train loss: 10.304917335510254\n",
      "Epoch: 0, iter: 119300, train loss: 10.304409980773926\n",
      "Epoch: 0, iter: 119400, train loss: 10.3062744140625\n",
      "Epoch: 0, iter: 119500, train loss: 10.305351257324219\n",
      "Epoch: 0, iter: 119600, train loss: 10.305929183959961\n",
      "Epoch: 0, iter: 119700, train loss: 10.306061744689941\n",
      "Epoch: 0, iter: 119800, train loss: 10.304695129394531\n",
      "Epoch: 0, iter: 119900, train loss: 10.304627418518066\n",
      "Epoch: 0, iter: 120000, train loss: 10.305044174194336\n",
      "Epoch: 0, iter: 120100, train loss: 10.30528450012207\n",
      "Epoch: 0, iter: 120200, train loss: 10.305869102478027\n",
      "Epoch: 0, iter: 120300, train loss: 10.305102348327637\n",
      "Epoch: 0, iter: 120400, train loss: 10.305488586425781\n",
      "Epoch: 0, iter: 120500, train loss: 10.305564880371094\n",
      "Epoch: 0, iter: 120600, train loss: 10.305390357971191\n",
      "Epoch: 0, iter: 120700, train loss: 10.305237770080566\n",
      "Epoch: 0, iter: 120800, train loss: 10.305219650268555\n",
      "Epoch: 0, iter: 120900, train loss: 10.305283546447754\n",
      "Epoch: 0, iter: 121000, train loss: 10.305066108703613\n",
      "Epoch: 0, iter: 121100, train loss: 10.304390907287598\n",
      "Epoch: 0, iter: 121200, train loss: 10.304878234863281\n",
      "Epoch: 0, iter: 121300, train loss: 10.305168151855469\n",
      "Epoch: 0, iter: 121400, train loss: 10.30483627319336\n",
      "Epoch: 0, iter: 121500, train loss: 10.305647850036621\n",
      "Epoch: 0, iter: 121600, train loss: 10.305126190185547\n",
      "Epoch: 0, iter: 121700, train loss: 10.305359840393066\n",
      "Epoch: 0, iter: 121800, train loss: 10.305185317993164\n",
      "Epoch: 0, iter: 121900, train loss: 10.305164337158203\n",
      "Epoch: 0, iter: 122000, train loss: 10.305868148803711\n",
      "Epoch: 0, iter: 122100, train loss: 10.306000709533691\n",
      "Epoch: 0, iter: 122200, train loss: 10.304586410522461\n",
      "Epoch: 0, iter: 122300, train loss: 10.305780410766602\n",
      "Epoch: 0, iter: 122400, train loss: 10.305810928344727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 122500, train loss: 10.304662704467773\n",
      "Epoch: 0, iter: 122600, train loss: 10.305166244506836\n",
      "Epoch: 0, iter: 122700, train loss: 10.304632186889648\n",
      "Epoch: 0, iter: 122800, train loss: 10.305739402770996\n",
      "Epoch: 0, iter: 122900, train loss: 10.305034637451172\n",
      "Epoch: 0, iter: 123000, train loss: 10.305333137512207\n",
      "Epoch: 0, iter: 123100, train loss: 10.305584907531738\n",
      "Epoch: 0, iter: 123200, train loss: 10.305283546447754\n",
      "Epoch: 0, iter: 123300, train loss: 10.30451774597168\n",
      "Epoch: 0, iter: 123400, train loss: 10.306100845336914\n",
      "Epoch: 0, iter: 123500, train loss: 10.304823875427246\n",
      "Epoch: 0, iter: 123600, train loss: 10.305303573608398\n",
      "Epoch: 0, iter: 123700, train loss: 10.305248260498047\n",
      "Epoch: 0, iter: 123800, train loss: 10.30434799194336\n",
      "Epoch: 0, iter: 123900, train loss: 10.305508613586426\n",
      "Epoch: 0, iter: 124000, train loss: 10.305286407470703\n",
      "Epoch: 0, iter: 124100, train loss: 10.304095268249512\n",
      "Epoch: 0, iter: 124200, train loss: 10.304803848266602\n",
      "Epoch: 0, iter: 124300, train loss: 10.304749488830566\n",
      "Epoch: 0, iter: 124400, train loss: 10.304556846618652\n",
      "Epoch: 0, iter: 124500, train loss: 10.30493450164795\n",
      "Epoch: 0, iter: 124600, train loss: 10.305566787719727\n",
      "Epoch: 0, iter: 124700, train loss: 10.305217742919922\n",
      "Epoch: 0, iter: 124800, train loss: 10.305780410766602\n",
      "Epoch: 0, iter: 124900, train loss: 10.307175636291504\n",
      "Epoch: 0, iter: 125000, train loss: 10.306544303894043\n",
      "Epoch: 0, iter: 125100, train loss: 10.305355072021484\n",
      "Epoch: 0, iter: 125200, train loss: 10.305933952331543\n",
      "Epoch: 0, iter: 125300, train loss: 10.305732727050781\n",
      "Epoch: 0, iter: 125400, train loss: 10.306148529052734\n",
      "Epoch: 0, iter: 125500, train loss: 10.304250717163086\n",
      "Epoch: 0, iter: 125600, train loss: 10.305510520935059\n",
      "Epoch: 0, iter: 125700, train loss: 10.306090354919434\n",
      "Epoch: 0, iter: 125800, train loss: 10.306034088134766\n",
      "Epoch: 0, iter: 125900, train loss: 10.305787086486816\n",
      "Epoch: 0, iter: 126000, train loss: 10.30508804321289\n",
      "Epoch: 0, iter: 126100, train loss: 10.304462432861328\n",
      "Epoch: 0, iter: 126200, train loss: 10.305316925048828\n",
      "Epoch: 0, iter: 126300, train loss: 10.305459022521973\n",
      "Epoch: 0, iter: 126400, train loss: 10.305646896362305\n",
      "Epoch: 0, iter: 126500, train loss: 10.305900573730469\n",
      "Epoch: 0, iter: 126600, train loss: 10.305673599243164\n",
      "Epoch: 0, iter: 126700, train loss: 10.30540657043457\n",
      "Epoch: 0, iter: 126800, train loss: 10.304534912109375\n",
      "Epoch: 0, iter: 126900, train loss: 10.304762840270996\n",
      "Epoch: 0, iter: 127000, train loss: 10.30484390258789\n",
      "Epoch: 0, iter: 127100, train loss: 10.305950164794922\n",
      "Epoch: 0, iter: 127200, train loss: 10.305489540100098\n",
      "Epoch: 0, iter: 127300, train loss: 10.305991172790527\n",
      "Epoch: 0, iter: 127400, train loss: 10.305920600891113\n",
      "Epoch: 0, iter: 127500, train loss: 10.305248260498047\n",
      "Epoch: 0, iter: 127600, train loss: 10.3052978515625\n",
      "Epoch: 0, iter: 127700, train loss: 10.305376052856445\n",
      "Epoch: 0, iter: 127800, train loss: 10.306116104125977\n",
      "Epoch: 0, iter: 127900, train loss: 10.30573844909668\n",
      "Epoch: 0, iter: 128000, train loss: 10.305248260498047\n",
      "Epoch: 0, iter: 128100, train loss: 10.305870056152344\n",
      "Epoch: 0, iter: 128200, train loss: 10.304125785827637\n",
      "Epoch: 0, iter: 128300, train loss: 10.30443000793457\n",
      "Epoch: 0, iter: 128400, train loss: 10.304856300354004\n",
      "Epoch: 0, iter: 128500, train loss: 10.305986404418945\n",
      "Epoch: 0, iter: 128600, train loss: 10.306066513061523\n",
      "Epoch: 0, iter: 128700, train loss: 10.305622100830078\n",
      "Epoch: 0, iter: 128800, train loss: 10.305001258850098\n",
      "Epoch: 0, iter: 128900, train loss: 10.304947853088379\n",
      "Epoch: 0, iter: 129000, train loss: 10.305842399597168\n",
      "Epoch: 0, iter: 129100, train loss: 10.305919647216797\n",
      "Epoch: 0, iter: 129200, train loss: 10.304540634155273\n",
      "Epoch: 0, iter: 129300, train loss: 10.304468154907227\n",
      "Epoch: 0, iter: 129400, train loss: 10.304920196533203\n",
      "Epoch: 0, iter: 129500, train loss: 10.305947303771973\n",
      "Epoch: 0, iter: 129600, train loss: 10.305996894836426\n",
      "Epoch: 0, iter: 129700, train loss: 10.304351806640625\n",
      "Epoch: 0, iter: 129800, train loss: 10.304313659667969\n",
      "Epoch: 0, iter: 129900, train loss: 10.305179595947266\n",
      "Epoch: 0, iter: 130000, train loss: 10.305559158325195\n",
      "Epoch: 0, iter: 130100, train loss: 10.305843353271484\n",
      "Epoch: 0, iter: 130200, train loss: 10.304925918579102\n",
      "Epoch: 0, iter: 130300, train loss: 10.305773735046387\n",
      "Epoch: 0, iter: 130400, train loss: 10.305620193481445\n",
      "Epoch: 0, iter: 130500, train loss: 10.305459976196289\n",
      "Epoch: 0, iter: 130600, train loss: 10.304913520812988\n",
      "Epoch: 0, iter: 130700, train loss: 10.305072784423828\n",
      "Epoch: 0, iter: 130800, train loss: 10.306065559387207\n",
      "Epoch: 0, iter: 130900, train loss: 10.305302619934082\n",
      "Epoch: 0, iter: 131000, train loss: 10.304412841796875\n",
      "Epoch: 0, iter: 131100, train loss: 10.305034637451172\n",
      "Epoch: 0, iter: 131200, train loss: 10.304965019226074\n",
      "Epoch: 0, iter: 131300, train loss: 10.305201530456543\n",
      "Epoch: 0, iter: 131400, train loss: 10.305960655212402\n",
      "Epoch: 0, iter: 131500, train loss: 10.305530548095703\n",
      "Epoch: 0, iter: 131600, train loss: 10.305285453796387\n",
      "Epoch: 0, iter: 131700, train loss: 10.304841041564941\n",
      "Epoch: 0, iter: 131800, train loss: 10.305059432983398\n",
      "Epoch: 0, iter: 131900, train loss: 10.305561065673828\n",
      "Epoch: 0, iter: 132000, train loss: 10.306368827819824\n",
      "Epoch: 0, iter: 132100, train loss: 10.30514907836914\n",
      "Epoch: 0, iter: 132200, train loss: 10.305946350097656\n",
      "Epoch: 0, iter: 132300, train loss: 10.3057279586792\n",
      "Epoch: 0, iter: 132400, train loss: 10.305193901062012\n",
      "Epoch: 0, iter: 132500, train loss: 10.304792404174805\n",
      "Epoch: 0, iter: 132600, train loss: 10.305197715759277\n",
      "Epoch: 0, iter: 132700, train loss: 10.30531120300293\n",
      "Epoch: 0, iter: 132800, train loss: 10.304437637329102\n",
      "Epoch: 0, iter: 132900, train loss: 10.305049896240234\n",
      "Epoch: 0, iter: 133000, train loss: 10.304712295532227\n",
      "Epoch: 0, iter: 133100, train loss: 10.305810928344727\n",
      "Epoch: 0, iter: 133200, train loss: 10.305145263671875\n",
      "Epoch: 0, iter: 133300, train loss: 10.305927276611328\n",
      "Epoch: 0, iter: 133400, train loss: 10.305102348327637\n",
      "Epoch: 0, iter: 133500, train loss: 10.304945945739746\n",
      "Epoch: 0, iter: 133600, train loss: 10.305630683898926\n",
      "Epoch: 0, iter: 133700, train loss: 10.30618667602539\n",
      "Epoch: 0, iter: 133800, train loss: 10.305344581604004\n",
      "Epoch: 0, iter: 133900, train loss: 10.305039405822754\n",
      "Epoch: 0, iter: 134000, train loss: 10.305606842041016\n",
      "Epoch: 0, iter: 134100, train loss: 10.304882049560547\n",
      "Epoch: 0, iter: 134200, train loss: 10.305035591125488\n",
      "Epoch: 0, iter: 134300, train loss: 10.305485725402832\n",
      "Epoch: 0, iter: 134400, train loss: 10.305127143859863\n",
      "Epoch: 0, iter: 134500, train loss: 10.306074142456055\n",
      "Epoch: 0, iter: 134600, train loss: 10.306209564208984\n",
      "Epoch: 0, iter: 134700, train loss: 10.304758071899414\n",
      "Epoch: 0, iter: 134800, train loss: 10.305048942565918\n",
      "Epoch: 0, iter: 134900, train loss: 10.30615234375\n",
      "Epoch: 0, iter: 135000, train loss: 10.305598258972168\n",
      "Epoch: 0, iter: 135100, train loss: 10.30508041381836\n",
      "Epoch: 0, iter: 135200, train loss: 10.304491996765137\n",
      "Epoch: 0, iter: 135300, train loss: 10.305591583251953\n",
      "Epoch: 0, iter: 135400, train loss: 10.305689811706543\n",
      "Epoch: 0, iter: 135500, train loss: 10.304996490478516\n",
      "Epoch: 0, iter: 135600, train loss: 10.305608749389648\n",
      "Epoch: 0, iter: 135700, train loss: 10.30459976196289\n",
      "Epoch: 0, iter: 135800, train loss: 10.305315971374512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-97ded423fb17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {}, iter: {}, train loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#         if i % 1000 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssd1/yaojiangtao/software/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train\n",
    "model = LanguageModel(vocab_size, embed_size, hidden_size).to(device)\n",
    "learning_rate = 4e-4\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "requires_grad = False\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "def evaluate(model, data_iter):\n",
    "    model.eval()\n",
    "    loss_all = 0.\n",
    "    count = 0.\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(BATCH_SIZE, requires_grad=False)\n",
    "        print(len(data_iter))\n",
    "        for i, (x, y) in enumerate(data_iter):\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output, hidden = model(x, hidden)\n",
    "            loss = loss_fn(output.view(-1, vocab_size), y.view(-1))\n",
    "            loss_all += loss * x.shape[0]\n",
    "            count += x.shape[0]\n",
    "    mode.train()\n",
    "    return loss_all / count\n",
    "    \n",
    "dev_loss_list = []\n",
    "model_path = './best_mode.pth'\n",
    "for epoch in range(2):\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "    for i, (x, y) in enumerate(train_iter):\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        output, hidden = model(x, hidden)\n",
    "        loss = loss_fn(output.view(-1, vocab_size), y.view(-1))\n",
    "        loss.requires_grad_(True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, iter: {}, train loss: {}\".format(epoch, i, loss))\n",
    "            \n",
    "#         if i % 1000 == 0:\n",
    "#             dev_loss = evaluate(model, dev_iter)\n",
    "#             print(\"Epoch: {}, iter: {}, dev loss: {}\".format(epoch, i, dev_loss))\n",
    "#             if len(dev_loss_list) == 0 or dev_loss < min(dev_loss_list):\n",
    "#                 torch.save(model.state_dict(), model_path)\n",
    "#             else:\n",
    "#                 scheduler.step()\n",
    "#             dev_loss_list.append(dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = LanguageModel(vocab_size, embed_size, hidden_size)\n",
    "test_model.load_state_dict(torch.load(model_path))\n",
    "words_list = []\n",
    "input_x = torch.randint(vocab_size, (1, 1), dtype=torch.long)\n",
    "hidden = test_model.init_hidden(1)\n",
    "for i in range(100):\n",
    "    output, hidden = model(input_x, hidden)\n",
    "    y = torch.argmax(output.view(-1))\n",
    "    input_x.fill_(y)\n",
    "    word = idx_to_word[y]\n",
    "    words_list.append(word)\n",
    "print(' '.join(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "rnn = nn.LSTM(10, 20, 2) #embedding_size, hidden_size, num_layer\n",
    "input = torch.randn(5, 3, 10)   #sequence_len, batch_size, embedding_size\n",
    "h0 = torch.randn(2, 3, 20)   #num_layer, batch_size, hidden_size\n",
    "c0 = torch.randn(2, 3, 20)   #num_layer, batch_size, hidden_size\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "#output: sequence_len, batch_size, embedding_size\n",
    "weights = next(rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
